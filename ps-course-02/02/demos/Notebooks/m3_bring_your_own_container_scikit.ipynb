{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Packaging your Algorithm \n",
    "\n",
    "Amazon SageMaker allows you to package your own algorithms and train and host it on Sagemaker. Here we package a scikit-learn implementation of decision trees for use with SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents of the container\n",
    "* **Dockerfile** describes how to build your Docker container image. \n",
    "* **build_and_push.sh** script uses the Dockerfile to build your container images and then pushes it to ECR.\n",
    "* **decision_trees** contains the files that will be installed in the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The files in the container are:\n",
    "\n",
    "* **nginx.conf**,the configuration file for the nginx front-end.\n",
    "* **predictor.py**,program implements the Flask web server and the decision tree predictions for this app.\n",
    "* **serve** program starts when the container is started for hosting, launches the gunicorn server which runs multiple instances of the Flask app defined in predictor.py. \n",
    "* **train**, program that is invoked when the container is run for training.\n",
    "* SageMaker will look to run an executable program named \"train\" for training and \"serve\" for hosting.\n",
    "* Or you can specify any ENTRYPOINT in your Dockerfile which has train() and serve() functions defined within.\n",
    "* **wsgi.py**,a small wrapper used to invoke the Flask app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and registering the container\n",
    "* Build the container image using docker build \n",
    "* Push the container image to ECR using docker push. \n",
    "* Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "* Looks for an ECR repository in the current account and current default region. If the repository doesn't exist, the script will create it.\n",
    "* Get the login command from ECR and execute it directly\n",
    "* Build the docker image locally with the image name \n",
    "* Push it to ECR with the full name.\n",
    "* On a SageMaker Notebook Instance, the docker daemon may need to be restarted in order to detect your network configuration correctly.(This is a known issue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Stopping docker: [  OK  ]\r\n",
      "Starting docker:\t.[  OK  ]\r\n",
      "Sending build context to Docker daemon  19.46kB\r",
      "\r\n",
      "Step 1/9 : FROM ubuntu:16.04\n",
      " ---> 0458a4468cbc\n",
      "Step 2/9 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 58e140ab7e46\n",
      "Step 3/9 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> b4f7f7e8b16f\n",
      "Step 4/9 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy scipy scikit-learn pandas flask gevent gunicorn &&         (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) &&         rm -rf /root/.cache\n",
      " ---> Using cache\n",
      " ---> 7fea61c87b2d\n",
      "Step 5/9 : ENV PYTHONUNBUFFERED TRUE\n",
      " ---> Using cache\n",
      " ---> fa6656aadb98\n",
      "Step 6/9 : ENV PYTHONDONTWRITEBYTECODE TRUE\n",
      " ---> Using cache\n",
      " ---> b25daae16532\n",
      "Step 7/9 : ENV PATH \"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> fef529184ace\n",
      "Step 8/9 : COPY decision_trees /opt/program\n",
      " ---> Using cache\n",
      " ---> 8f8a3d46fb5c\n",
      "Step 9/9 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 183f3c4037f0\n",
      "Successfully built 183f3c4037f0\n",
      "Successfully tagged decision-trees-sample:latest\n",
      "The push refers to a repository [324118574079.dkr.ecr.us-east-2.amazonaws.com/decision-trees-sample]\n",
      "7849c58a0805: Preparing\n",
      "85bf8224afc7: Preparing\n",
      "aecd43f19062: Preparing\n",
      "6f4ce6b88849: Preparing\n",
      "92914665e7f6: Preparing\n",
      "c98ef191df4b: Preparing\n",
      "9c7183e0ea88: Preparing\n",
      "ff986b10a018: Preparing\n",
      "9c7183e0ea88: Waiting\n",
      "ff986b10a018: Waiting\n",
      "c98ef191df4b: Waiting\n",
      "aecd43f19062: Layer already exists\n",
      "85bf8224afc7: Layer already exists\n",
      "6f4ce6b88849: Layer already exists\n",
      "92914665e7f6: Layer already exists\n",
      "7849c58a0805: Layer already exists\n",
      "c98ef191df4b: Layer already exists\n",
      "ff986b10a018: Layer already exists\n",
      "9c7183e0ea88: Layer already exists\n",
      "latest: digest: sha256:e9765c9c142cbcf60b99a22b0870b450ab8cf28aed115baf7b61468ce253fbc4 size: 1990\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "algorithm_name=decision-trees-sample\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x decision_trees/train\n",
    "chmod +x decision_trees/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "if [ -d \"/home/ec2-user/SageMaker\" ]; then\n",
    "  sudo service docker restart\n",
    "fi\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training and Hosting the Algorithm\n",
    "\n",
    "Once you have your container packaged, you can use it to train and serve models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages \n",
    "* os -  provides a portable way of using operating system dependent functionality.\n",
    "* gmtime - Convert a time expressed in seconds since the epoch to a struct_time in UTC.\n",
    "* strftime - Convert a tuple or struct_time representing a time as returned by gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing some standard python packages \n",
    "* csv- module provides objects to read and write sequences.\n",
    "* itertools - module implements a number of iterator building blocks.\n",
    "* numpy  - package for scientific computing with Python.\n",
    "* pandas - library providing data structures and data analysis tools for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing amazon packages\n",
    "* boto3 - The AWS SDK for Python to write software that uses Amazon services like S3 and EC2.\n",
    "* psycopg2 - popular PostgreSQL database adapter for the Python\n",
    "* sagemaker - Python SDK for training and deploying machine learning models on Amazon SageMaker.\n",
    "* get_execution_role - Return the role ARN whose credentials are used to call the API.\n",
    "* csv_serializer - Defines csv as the behavior for serialization of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import psycopg2\n",
    "import sagemaker as sage\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con=psycopg2.connect(dbname= 'loonydb1', host='myloony-db.cwwbfulhovv2.us-east-2.redshift.amazonaws.com', \n",
    "port= '5439', user= 'masteruser', password= 'Password123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query=\"select * from public.irisdata ;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = open('iris.csv','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c= csv.writer(fp, lineterminator='\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('setosa', 5.1, 3.5, 1.4, 0.2)\n",
      "('setosa', 4.7, 3.2, 1.3, 0.2)\n",
      "('setosa', 5.0, 3.6, 1.4, 0.2)\n",
      "('setosa', 4.6, 3.4, 1.4, 0.3)\n",
      "('setosa', 4.4, 2.9, 1.4, 0.2)\n",
      "('setosa', 5.4, 3.7, 1.5, 0.2)\n",
      "('setosa', 4.8, 3.0, 1.4, 0.1)\n",
      "('setosa', 5.8, 4.0, 1.2, 0.2)\n",
      "('setosa', 5.4, 3.9, 1.3, 0.4)\n",
      "('setosa', 5.7, 3.8, 1.7, 0.3)\n",
      "('setosa', 5.4, 3.4, 1.7, 0.2)\n",
      "('setosa', 4.6, 3.6, 1.0, 0.2)\n",
      "('setosa', 4.8, 3.4, 1.9, 0.2)\n",
      "('setosa', 5.0, 3.4, 1.6, 0.4)\n",
      "('setosa', 5.2, 3.4, 1.4, 0.2)\n",
      "('setosa', 4.8, 3.1, 1.6, 0.2)\n",
      "('setosa', 5.2, 4.1, 1.5, 0.1)\n",
      "('setosa', 4.9, 3.1, 1.5, 0.2)\n",
      "('setosa', 5.5, 3.5, 1.3, 0.2)\n",
      "('setosa', 4.4, 3.0, 1.3, 0.2)\n",
      "('setosa', 5.0, 3.5, 1.3, 0.3)\n",
      "('setosa', 4.4, 3.2, 1.3, 0.2)\n",
      "('setosa', 5.1, 3.8, 1.9, 0.4)\n",
      "('setosa', 5.1, 3.8, 1.6, 0.2)\n",
      "('setosa', 5.3, 3.7, 1.5, 0.2)\n",
      "('versicolor', 7.0, 3.2, 4.7, 1.4)\n",
      "('versicolor', 6.9, 3.1, 4.9, 1.5)\n",
      "('versicolor', 6.5, 2.8, 4.6, 1.5)\n",
      "('versicolor', 6.3, 3.3, 4.7, 1.6)\n",
      "('versicolor', 6.6, 2.9, 4.6, 1.3)\n",
      "('versicolor', 5.0, 2.0, 3.5, 1.0)\n",
      "('versicolor', 6.0, 2.2, 4.0, 1.0)\n",
      "('versicolor', 5.6, 2.9, 3.6, 1.3)\n",
      "('versicolor', 5.6, 3.0, 4.5, 1.5)\n",
      "('versicolor', 6.2, 2.2, 4.5, 1.5)\n",
      "('versicolor', 5.9, 3.2, 4.8, 1.8)\n",
      "('versicolor', 6.3, 2.5, 4.9, 1.5)\n",
      "('versicolor', 6.4, 2.9, 4.3, 1.3)\n",
      "('versicolor', 6.8, 2.8, 4.8, 1.4)\n",
      "('versicolor', 6.0, 2.9, 4.5, 1.5)\n",
      "('versicolor', 5.5, 2.4, 3.8, 1.1)\n",
      "('versicolor', 5.8, 2.7, 3.9, 1.2)\n",
      "('versicolor', 5.4, 3.0, 4.5, 1.5)\n",
      "('versicolor', 6.7, 3.1, 4.7, 1.5)\n",
      "('versicolor', 5.6, 3.0, 4.1, 1.3)\n",
      "('versicolor', 5.5, 2.6, 4.4, 1.2)\n",
      "('versicolor', 5.8, 2.6, 4.0, 1.2)\n",
      "('versicolor', 5.6, 2.7, 4.2, 1.3)\n",
      "('versicolor', 5.7, 2.9, 4.2, 1.3)\n",
      "('versicolor', 5.1, 2.5, 3.0, 1.1)\n",
      "('virginica', 6.3, 3.3, 6.0, 2.5)\n",
      "('virginica', 7.1, 3.0, 5.9, 2.1)\n",
      "('virginica', 6.5, 3.0, 5.8, 2.2)\n",
      "('virginica', 4.9, 2.5, 4.5, 1.7)\n",
      "('virginica', 6.7, 2.5, 5.8, 1.8)\n",
      "('virginica', 6.5, 3.2, 5.1, 2.0)\n",
      "('virginica', 6.8, 3.0, 5.5, 2.1)\n",
      "('virginica', 5.8, 2.8, 5.1, 2.4)\n",
      "('virginica', 6.5, 3.0, 5.5, 1.8)\n",
      "('virginica', 7.7, 2.6, 6.9, 2.3)\n",
      "('virginica', 6.9, 3.2, 5.7, 2.3)\n",
      "('virginica', 7.7, 2.8, 6.7, 2.0)\n",
      "('virginica', 6.7, 3.3, 5.7, 2.1)\n",
      "('virginica', 6.2, 2.8, 4.8, 1.8)\n",
      "('virginica', 6.4, 2.8, 5.6, 2.1)\n",
      "('virginica', 7.4, 2.8, 6.1, 1.9)\n",
      "('virginica', 6.4, 2.8, 5.6, 2.2)\n",
      "('virginica', 6.1, 2.6, 5.6, 1.4)\n",
      "('virginica', 6.3, 3.4, 5.6, 2.4)\n",
      "('virginica', 6.0, 3.0, 4.8, 1.8)\n",
      "('virginica', 6.7, 3.1, 5.6, 2.4)\n",
      "('virginica', 5.8, 2.7, 5.1, 1.9)\n",
      "('virginica', 6.7, 3.3, 5.7, 2.5)\n",
      "('virginica', 6.3, 2.5, 5.0, 1.9)\n",
      "('virginica', 6.2, 3.4, 5.4, 2.3)\n",
      "('setosa', 4.9, 3.0, 1.4, 0.2)\n",
      "('setosa', 4.6, 3.1, 1.5, 0.2)\n",
      "('setosa', 5.4, 3.9, 1.7, 0.4)\n",
      "('setosa', 5.0, 3.4, 1.5, 0.2)\n",
      "('setosa', 4.9, 3.1, 1.5, 0.1)\n",
      "('setosa', 4.8, 3.4, 1.6, 0.2)\n",
      "('setosa', 4.3, 3.0, 1.1, 0.1)\n",
      "('setosa', 5.7, 4.4, 1.5, 0.4)\n",
      "('setosa', 5.1, 3.5, 1.4, 0.3)\n",
      "('setosa', 5.1, 3.8, 1.5, 0.3)\n",
      "('setosa', 5.1, 3.7, 1.5, 0.4)\n",
      "('setosa', 5.1, 3.3, 1.7, 0.5)\n",
      "('setosa', 5.0, 3.0, 1.6, 0.2)\n",
      "('setosa', 5.2, 3.5, 1.5, 0.2)\n",
      "('setosa', 4.7, 3.2, 1.6, 0.2)\n",
      "('setosa', 5.4, 3.4, 1.5, 0.4)\n",
      "('setosa', 5.5, 4.2, 1.4, 0.2)\n",
      "('setosa', 5.0, 3.2, 1.2, 0.2)\n",
      "('setosa', 4.9, 3.6, 1.4, 0.1)\n",
      "('setosa', 5.1, 3.4, 1.5, 0.2)\n",
      "('setosa', 4.5, 2.3, 1.3, 0.3)\n",
      "('setosa', 5.0, 3.5, 1.6, 0.6)\n",
      "('setosa', 4.8, 3.0, 1.4, 0.3)\n",
      "('setosa', 4.6, 3.2, 1.4, 0.2)\n",
      "('setosa', 5.0, 3.3, 1.4, 0.2)\n",
      "('versicolor', 6.4, 3.2, 4.5, 1.5)\n",
      "('versicolor', 5.5, 2.3, 4.0, 1.3)\n",
      "('versicolor', 5.7, 2.8, 4.5, 1.3)\n",
      "('versicolor', 4.9, 2.4, 3.3, 1.0)\n",
      "('versicolor', 5.2, 2.7, 3.9, 1.4)\n",
      "('versicolor', 5.9, 3.0, 4.2, 1.5)\n",
      "('versicolor', 6.1, 2.9, 4.7, 1.4)\n",
      "('versicolor', 6.7, 3.1, 4.4, 1.4)\n",
      "('versicolor', 5.8, 2.7, 4.1, 1.0)\n",
      "('versicolor', 5.6, 2.5, 3.9, 1.1)\n",
      "('versicolor', 6.1, 2.8, 4.0, 1.3)\n",
      "('versicolor', 6.1, 2.8, 4.7, 1.2)\n",
      "('versicolor', 6.6, 3.0, 4.4, 1.4)\n",
      "('versicolor', 6.7, 3.0, 5.0, 1.7)\n",
      "('versicolor', 5.7, 2.6, 3.5, 1.0)\n",
      "('versicolor', 5.5, 2.4, 3.7, 1.0)\n",
      "('versicolor', 6.0, 2.7, 5.1, 1.6)\n",
      "('versicolor', 6.0, 3.4, 4.5, 1.6)\n",
      "('versicolor', 6.3, 2.3, 4.4, 1.3)\n",
      "('versicolor', 5.5, 2.5, 4.0, 1.3)\n",
      "('versicolor', 6.1, 3.0, 4.6, 1.4)\n",
      "('versicolor', 5.0, 2.3, 3.3, 1.0)\n",
      "('versicolor', 5.7, 3.0, 4.2, 1.2)\n",
      "('versicolor', 6.2, 2.9, 4.3, 1.3)\n",
      "('versicolor', 5.7, 2.8, 4.1, 1.3)\n",
      "('virginica', 5.8, 2.7, 5.1, 1.9)\n",
      "('virginica', 6.3, 2.9, 5.6, 1.8)\n",
      "('virginica', 7.6, 3.0, 6.6, 2.1)\n",
      "('virginica', 7.3, 2.9, 6.3, 1.8)\n",
      "('virginica', 7.2, 3.6, 6.1, 2.5)\n",
      "('virginica', 6.4, 2.7, 5.3, 1.9)\n",
      "('virginica', 5.7, 2.5, 5.0, 2.0)\n",
      "('virginica', 6.4, 3.2, 5.3, 2.3)\n",
      "('virginica', 7.7, 3.8, 6.7, 2.2)\n",
      "('virginica', 6.0, 2.2, 5.0, 1.5)\n",
      "('virginica', 5.6, 2.8, 4.9, 2.0)\n",
      "('virginica', 6.3, 2.7, 4.9, 1.8)\n",
      "('virginica', 7.2, 3.2, 6.0, 1.8)\n",
      "('virginica', 6.1, 3.0, 4.9, 1.8)\n",
      "('virginica', 7.2, 3.0, 5.8, 1.6)\n",
      "('virginica', 7.9, 3.8, 6.4, 2.0)\n",
      "('virginica', 6.3, 2.8, 5.1, 1.5)\n",
      "('virginica', 7.7, 3.0, 6.1, 2.3)\n",
      "('virginica', 6.4, 3.1, 5.5, 1.8)\n",
      "('virginica', 6.9, 3.1, 5.4, 2.1)\n",
      "('virginica', 6.9, 3.1, 5.1, 2.3)\n",
      "('virginica', 6.8, 3.2, 5.9, 2.3)\n",
      "('virginica', 6.7, 3.0, 5.2, 2.3)\n",
      "('virginica', 6.5, 3.0, 5.2, 2.0)\n",
      "('virginica', 5.9, 3.0, 5.1, 1.8)\n"
     ]
    }
   ],
   "source": [
    "for row in results:\n",
    "    print (row)\n",
    "    c.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "* Set the bucket path\n",
    "* Create a sagemaker session\n",
    "* Create a bucket and upload the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'scikit-byoc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_location = sess.upload_data('iris.csv', key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting the model \n",
    "* Get the account and region information\n",
    "* Get the container image\n",
    "* Get the IAM role credentials\n",
    "* Instantiate an estimator\n",
    "* Invoke the fit method to train the model\n",
    "* Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'324118574079'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = sess.boto_session.region_name\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = '{}.dkr.ecr.{}.amazonaws.com/decision-trees-sample'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::324118574079:role/service-role/AmazonSageMaker-ExecutionRole-20180209T192191'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: decision-trees-sample-2018-03-10-09-49-15-351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................\n",
      "\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31mTraining complete.\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "tree.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = tree.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model\n",
    "* extract some of the data we used for training\n",
    "* pass in the data to the predictor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape=pd.read_csv(\"iris.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = shape[50:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = df[0].values.T.tolist()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X =df.drop(df.columns[0], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = predictor.predict(test_X.values).decode('utf-8')\n",
    "results=results.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (np.array(names) == np.array(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
