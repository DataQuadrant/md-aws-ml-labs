{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reference:  \n",
    "https://github.com/ACloudGuru-Resources/Course_AWS_Certified_Machine_Learning/blob/master/Chapter6/ufo-modeling-lab.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UFO Sightings K-Means Clustering\n",
    "### Modeling Lab\n",
    "\n",
    "The goal of this notebook is to analyze where Mr. K should build his extraterrestrial life facilities using the K-Means algorithm. \n",
    "\n",
    "What we plan on accomplishing is the following:\n",
    "1. [Load dataset onto Notebook instance from S3](#Step-1:-Loading-the-data-from-Amazon-S3)\n",
    "2. [Cleaning, transforming, and preparing the data](#Step-2:-Cleaning,-transforming,-and-preparing-the-data)\n",
    "3. [Create and train our model](#Step-3:-Create-and-train-our-model)\n",
    "4. [Viewing the results](#Step-4:-Viewing-the-results)\n",
    "5. [Visualize using QuickSight](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First let's go ahead and import all the needed libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Loading the data from Amazon S3\n",
    "Next, lets get the UFO sightings data that is stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role = get_execution_role()\n",
    "\n",
    "def resolve_sm_role():\n",
    "    client = boto3.client('iam', region_name='us-east-2')\n",
    "    response_roles = client.list_roles(\n",
    "        PathPrefix='/',\n",
    "        # Marker='string',\n",
    "        MaxItems=999\n",
    "    )\n",
    "    for role in response_roles['Roles']:\n",
    "        if role['RoleName'].startswith('AmazonSageMaker-ExecutionRole-'):\n",
    "            print('Resolved SageMaker IAM Role to: ' + str(role))\n",
    "            return role['Arn']\n",
    "    raise Exception('Could not resolve what should be the SageMaker role to be used')\n",
    "\n",
    "# this is the role created by sagemaker notebook on aws\n",
    "role_arn = resolve_sm_role()\n",
    "print(role_arn)\n",
    "\n",
    "role = role_arn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "bucket = 'md-ml-labs-bucket'\n",
    "prefix = 'acg'\n",
    "data_key = 'ufo_fullset.csv'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, prefix, data_key)\n",
    "\n",
    "df = pd.read_csv(data_location, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Cleaning, transforming, and preparing the data\n",
    "Create another DataFrame with just the latitude and longitude attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = df[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values = df_geo.isnull().values.any()\n",
    "print('Are there any missing values? {}'.format(missing_values))\n",
    "\n",
    "if(missing_values):\n",
    "    df_geo[df_geo.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, let's go ahead and transform the pandas DataFrame (our dataset) into a numpy.ndarray. When we do this each row is converted to a Record object. According to the documentation, this is what the K-Means algorithm expects as training data. This is what we will use as training data for our model.\n",
    "\n",
    "[See the documentation for input training](https://sagemaker.readthedocs.io/en/stable/kmeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_geo.values.astype('float32')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Create and train our model\n",
    "In this step we will import and use the built-in SageMaker K-Means algorithm. We will set the number of cluster to 10 (for our 10 sensors), specify the instance type we want to train on, and the location of where we want our model artifact to live. \n",
    "\n",
    "[See the documentation of hyperparameters here](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means-api-config.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "output_location = 's3://' + bucket + '/model-artifacts'\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "               train_instance_count=1,\n",
    "               train_instance_type='ml.c4.xlarge',\n",
    "               output_path=output_location,\n",
    "               k=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'kmeans-geo-job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "print('Here is the job name {}'.format(job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans.fit(kmeans.record_set(data_train), job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Viewing the results\n",
    "In this step we will take a look at the model artifact SageMaker created for us and stored onto S3. We have to do a few special things to see the latitude and longitude for our 10 clusters (and the center points of those clusters)\n",
    "\n",
    "[See the documentation of deserilization here](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization)\n",
    "\n",
    "At this point we need to \"deserilize\" the model artifact. Here we are going to open and review them in our notebook instance. We can unzip the model artifact which will contain model_algo-1. This is just a serialized Apache MXNet object. From here we can load that serialized object into a numpy.ndarray and then extract the clustered centroids from the numpy.ndarray.\n",
    "\n",
    "After we extract the results into a DataFrame of latitudes and longitudes, we can create a CSV with that data, load it onto S3 and then visualize it with QuickSight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_key = 'model-artifacts/' + job_name + '/output/model.tar.gz'\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "Kmeans_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_centroids_kmeans = pd.DataFrame(Kmeans_model_params[0].asnumpy())\n",
    "cluster_centroids_kmeans.columns=df_geo.columns\n",
    "cluster_centroids_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's go ahead and upload this dataset onto S3 and view within QuickSight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "cluster_centroids_kmeans.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'results/ten_locations_kmeans.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}