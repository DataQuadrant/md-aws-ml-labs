{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own Scikit container\n",
    "\n",
    "reference:  \n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reasons:  \n",
    "- a specific version is not supported\n",
    "- config specific dependencies\n",
    "- use diff training/hosting than the one provided\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How Amazon SM runs your training image:  \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html\n",
    "\n",
    "How Amazon SM provides training information:  \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html\n",
    "\n",
    "Scikit Decision Trees \n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "\n",
    "## Training\n",
    "\n",
    "/opt/ml  \n",
    "├── input  \n",
    "│   ├── config  \n",
    "│   │   ├── hyperparameters.json  \n",
    "│   │   └── resourceConfig.json  \n",
    "│   └── data  \n",
    "│       └── <channel_name>  \n",
    "│           └── <_input data>  \n",
    "├── model  \n",
    "│   └── <model files>  \n",
    "└── output  \n",
    "    └── failure  \n",
    "\n",
    "\n",
    "## Hosting\n",
    "/opt/ml  \n",
    "└── model  \n",
    "    └── <_model files>  \n",
    "    \n",
    "\n",
    "## The Container\n",
    "\n",
    "├── Dockerfile    \n",
    "├── build_and_push.sh  \n",
    "└── decision_trees  \n",
    "    ├── nginx.conf   \n",
    "    ├── predictor.py  \n",
    "    ├── serve  \n",
    "    ├── train   \n",
    "    └── wsgi.py  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* __nginx.conf__ is the configuration file for the nginx front-end. Generally, you should be able to take this file as-is.\n",
    "* _predictor.py_ is the program that actually implements the Flask web server and the decision tree predictions for this app. You'll want to customize the actual prediction parts to your application. Since this algorithm is simple, we do all the processing here in this file, but you may choose to have separate files for implementing your custom logic.\n",
    "* serve is the program started when the container is started for hosting. It simply launches the gunicorn server which runs multiple instances of the Flask app defined in predictor.py. You should be able to take this file as-is.\n",
    "* train is the program that is invoked when the container is run for training. You will modify this program to implement your training algorithm.\n",
    "* wsgi.py is a small wrapper used to invoke the Flask app. You should be able to take this file as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}