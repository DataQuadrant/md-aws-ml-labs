{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Apache MXNet Module API with SageMaker Training and Batch Transformation\n",
    "\n",
    "The SageMaker Python SDK makes it easy to train MXNet models and use them for batch transformation. In this example, we train a simple neural network using the Apache MXNet [Module API](https://mxnet.incubator.apache.org/api/python/module.html) and the MNIST dataset. The MNIST dataset is widely used for handwritten digit classification, and consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60,000 training images and subsequently test its classification accuracy on the 10,000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, we define a few variables that are be needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "sample_data_bucket = 'sagemaker-sample-data-{}'.format(region)\n",
    "\n",
    "# S3 bucket for saving files. Feel free to redefine this variable to the bucket of your choice.\n",
    "# bucket = sagemaker_session.default_bucket()\n",
    "bucket = 'md-backup-bucket-01'\n",
    "\n",
    "# Bucket location where your custom code will be saved in the tar.gz format.\n",
    "custom_code_upload_location = 's3://{}/mxnet-mnist-example/code'.format(bucket)\n",
    "\n",
    "# Bucket location where results of model training are saved.\n",
    "model_artifacts_location = 's3://{}/mxnet-mnist-example/artifacts'.format(bucket)\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "# role = get_execution_role()\n",
    "role = 'arn:aws:iam::558157414092:role/service-role/AmazonSageMaker-ExecutionRole-20200523T082014'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and inference script\n",
    "\n",
    "The `mnist.py` script provides all the code we need for training and and inference. The script also checkpoints the model at the end of every epoch and saves the model graph, params and optimizer state in the folder `/opt/ml/checkpoints`. If the folder path does not exist then it skips checkpointing. The script we use is adaptated from the Apache MXNet [MNIST tutorial](https://mxnet.incubator.apache.org/tutorials/python/mnist.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgzip\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mstruct\u001b[39;49;00m\n\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmx\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32mload_data\u001b[39;49;00m(path):\n    \u001b[34mwith\u001b[39;49;00m gzip.open(find_file(path, \u001b[33m\"\u001b[39;49;00m\u001b[33mlabels.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)) \u001b[34mas\u001b[39;49;00m flbl:\n        struct.unpack(\u001b[33m\"\u001b[39;49;00m\u001b[33m>II\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flbl.read(\u001b[34m8\u001b[39;49;00m))\n        labels = np.fromstring(flbl.read(), dtype=np.int8)\n    \u001b[34mwith\u001b[39;49;00m gzip.open(find_file(path, \u001b[33m\"\u001b[39;49;00m\u001b[33mimages.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)) \u001b[34mas\u001b[39;49;00m fimg:\n        _, _, rows, cols = struct.unpack(\u001b[33m\"\u001b[39;49;00m\u001b[33m>IIII\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, fimg.read(\u001b[34m16\u001b[39;49;00m))\n        images = np.fromstring(fimg.read(), dtype=np.uint8).reshape(\u001b[36mlen\u001b[39;49;00m(labels), rows, cols)\n        images = images.reshape(images.shape[\u001b[34m0\u001b[39;49;00m], \u001b[34m1\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m).astype(np.float32) / \u001b[34m255\u001b[39;49;00m\n    \u001b[34mreturn\u001b[39;49;00m labels, images\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32mfind_file\u001b[39;49;00m(root_path, file_name):\n    \u001b[34mfor\u001b[39;49;00m root, dirs, files \u001b[35min\u001b[39;49;00m os.walk(root_path):\n        \u001b[34mif\u001b[39;49;00m file_name \u001b[35min\u001b[39;49;00m files:\n            \u001b[34mreturn\u001b[39;49;00m os.path.join(root, file_name)\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_graph\u001b[39;49;00m():\n    data = mx.sym.var(\u001b[33m'\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n    data = mx.sym.flatten(data=data)\n    fc1 = mx.sym.FullyConnected(data=data, num_hidden=\u001b[34m128\u001b[39;49;00m)\n    act1 = mx.sym.Activation(data=fc1, act_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n    fc2 = mx.sym.FullyConnected(data=act1, num_hidden=\u001b[34m64\u001b[39;49;00m)\n    act2 = mx.sym.Activation(data=fc2, act_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n    fc3 = mx.sym.FullyConnected(data=act2, num_hidden=\u001b[34m10\u001b[39;49;00m)\n    \u001b[34mreturn\u001b[39;49;00m mx.sym.SoftmaxOutput(data=fc3, name=\u001b[33m'\u001b[39;49;00m\u001b[33msoftmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32mget_training_context\u001b[39;49;00m(num_gpus):\n    \u001b[34mif\u001b[39;49;00m num_gpus:\n        \u001b[34mreturn\u001b[39;49;00m [mx.gpu(i) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(num_gpus)]\n    \u001b[34melse\u001b[39;49;00m:\n        \u001b[34mreturn\u001b[39;49;00m mx.cpu()\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(batch_size, epochs, learning_rate, num_gpus, training_channel, testing_channel,\n          hosts, current_host, model_dir):\n    checkpoints_dir = \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/checkpoints\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n    checkpoints_enabled = os.path.exists(checkpoints_dir)\n\n    (train_labels, train_images) = load_data(training_channel)\n    (test_labels, test_images) = load_data(testing_channel)\n    \u001b[37m# Data parallel training - shard the data so each host\u001b[39;49;00m\n    \u001b[37m# only trains on a subset of the total data.\u001b[39;49;00m\n    shard_size = \u001b[36mlen\u001b[39;49;00m(train_images) // \u001b[36mlen\u001b[39;49;00m(hosts)\n    \u001b[34mfor\u001b[39;49;00m i, host \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(hosts):\n        \u001b[34mif\u001b[39;49;00m host == current_host:\n            start = shard_size * i\n            end = start + shard_size\n            \u001b[34mbreak\u001b[39;49;00m\n\n    train_iter = mx.io.NDArrayIter(train_images[start:end], train_labels[start:end], batch_size,\n                                   shuffle=\u001b[34mTrue\u001b[39;49;00m)\n    val_iter = mx.io.NDArrayIter(test_images, test_labels, batch_size)\n\n    logging.getLogger().setLevel(logging.DEBUG)\n\n    kvstore = \u001b[33m'\u001b[39;49;00m\u001b[33mlocal\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(hosts) == \u001b[34m1\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mdist_sync\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n\n    mlp_model = mx.mod.Module(symbol=build_graph(),\n                              context=get_training_context(num_gpus))\n\n    checkpoint_callback = \u001b[34mNone\u001b[39;49;00m\n    \u001b[34mif\u001b[39;49;00m checkpoints_enabled:\n        \u001b[37m# Create a checkpoint callback that checkpoints the model params and\u001b[39;49;00m\n        \u001b[37m# the optimizer state at the given path after every epoch.\u001b[39;49;00m\n        checkpoint_callback = mx.callback.module_checkpoint(mlp_model,\n                                                            os.path.join(checkpoints_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmnist\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\n                                                            period=\u001b[34m1\u001b[39;49;00m,\n                                                            save_optimizer_states=\u001b[34mTrue\u001b[39;49;00m)\n    mlp_model.fit(train_iter,\n                  eval_data=val_iter,\n                  kvstore=kvstore,\n                  optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33msgd\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n                  optimizer_params={\u001b[33m'\u001b[39;49;00m\u001b[33mlearning_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: learning_rate},\n                  eval_metric=\u001b[33m'\u001b[39;49;00m\u001b[33macc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n                  epoch_end_callback=checkpoint_callback,\n                  batch_end_callback=mx.callback.Speedometer(batch_size, \u001b[34m100\u001b[39;49;00m),\n                  num_epoch=epochs)\n\n    \u001b[34mif\u001b[39;49;00m current_host == hosts[\u001b[34m0\u001b[39;49;00m]:\n        save(model_dir, mlp_model)\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32msave\u001b[39;49;00m(model_dir, model):\n    model.symbol.save(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel-symbol.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n    model.save_params(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel-0000.params\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n\n    signature = [{\u001b[33m'\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: data_desc.name, \u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [dim \u001b[34mfor\u001b[39;49;00m dim \u001b[35min\u001b[39;49;00m data_desc.shape]}\n                 \u001b[34mfor\u001b[39;49;00m data_desc \u001b[35min\u001b[39;49;00m model.data_shapes]\n    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel-shapes.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n        json.dump(signature, f)\n\n\n\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--learning-rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m)\n\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n\n    \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\n\n\n\u001b[37m### NOTE: this function cannot use MXNet\u001b[39;49;00m\n\u001b[34mdef\u001b[39;49;00m \u001b[32mneo_preprocess\u001b[39;49;00m(payload, content_type):\n    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\n\n    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user-defined pre-processing function\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n\n    \u001b[34mif\u001b[39;49;00m content_type != \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/vnd+python.numpy+binary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mContent type must be application/vnd+python.numpy+binary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n\n    f = io.BytesIO(payload)\n    \u001b[34mreturn\u001b[39;49;00m np.load(f)\n\n\n\u001b[37m### NOTE: this function cannot use MXNet\u001b[39;49;00m\n\u001b[34mdef\u001b[39;49;00m \u001b[32mneo_postprocess\u001b[39;49;00m(result):\n    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n\n    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user-defined post-processing function\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n\n    \u001b[37m# Softmax (assumes batch size 1)\u001b[39;49;00m\n    result = np.squeeze(result)\n    result_exp = np.exp(result - np.max(result))\n    result = result_exp / np.sum(result_exp)\n\n    response_body = json.dumps(result.tolist())\n    content_type = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n\n    \u001b[34mreturn\u001b[39;49;00m response_body, content_type\n\n\n\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n    args = parse_args()\n    num_gpus = \u001b[36mint\u001b[39;49;00m(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n\n    train(args.batch_size, args.epochs, args.learning_rate, num_gpus, args.train, args.test,\n          args.hosts, args.current_host, args.model_dir)\n"
    }
   ],
   "source": [
    "!pygmentize mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker's MXNet estimator class\n",
    "\n",
    "The SageMaker ```MXNet``` estimator allows us to run single machine or distributed training in SageMaker, using CPU or GPU-based instances.\n",
    "\n",
    "When we create the estimator, we pass in the filename of our training script, the name of our IAM execution role, and the S3 locations we defined in the setup section. We also provide a few other parameters. ``train_instance_count`` and ``train_instance_type`` determine the number and type of SageMaker instances that are used for the training job. The ``hyperparameters`` parameter is a ``dict`` of values that is passed to your training script -- you can see how to access these values in the ``mnist.py`` script above.\n",
    "\n",
    "For this example, we choose one ``ml.m4.xlarge`` instance for our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "mnist_estimator = MXNet(entry_point='mnist.py',\n",
    "                        role=role,\n",
    "                        output_path=model_artifacts_location,\n",
    "                        code_location=custom_code_upload_location,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.m4.xlarge',\n",
    "                        framework_version='1.6.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters={'learning-rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a training job\n",
    "\n",
    "After we've constructed our `MXNet` object, we can fit it using data stored in S3. Below we run SageMaker training on two input channels: train and test.\n",
    "\n",
    "During training, SageMaker makes this data stored in S3 available in the local filesystem where the `mnist.py` script is running. The script then simply loads the train and test data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-05-26 15:49:43 Starting - Starting the training job...\n2020-05-26 15:49:44 Starting - Launching requested ML instances......\n2020-05-26 15:50:49 Starting - Preparing the instances for training...\n2020-05-26 15:51:33 Downloading - Downloading input data...\n2020-05-26 15:52:12 Training - Training image download completed. Training in progress..\u001b[34m2020-05-26 15:52:13,706 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n\u001b[34m2020-05-26 15:52:13,710 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n\u001b[34m2020-05-26 15:52:13,726 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"learning-rate\":0.1}', 'SM_USER_ENTRY_POINT': 'mnist.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"test\",\"train\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'mnist', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://md-backup-bucket-01/mxnet-mnist-example/code/mxnet-training-2020-05-26-15-49-42-296/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"learning-rate\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-05-26-15-49-42-296\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://md-backup-bucket-01/mxnet-mnist-example/code/mxnet-training-2020-05-26-15-49-42-296/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}', 'SM_USER_ARGS': '[\"--learning-rate\",\"0.1\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TEST': '/opt/ml/input/data/test', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_HP_LEARNING-RATE': '0.1'}\u001b[0m\n\u001b[34m2020-05-26 15:52:14,018 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n\u001b[34mGenerating setup.py\u001b[0m\n\u001b[34m2020-05-26 15:52:14,018 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n\u001b[34m2020-05-26 15:52:14,018 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n\u001b[34m2020-05-26 15:52:14,019 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n\u001b[34m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n\u001b[34mProcessing /tmp/tmpxslv36ll/module_dir\u001b[0m\n\u001b[34mInstalling collected packages: default-user-module-name\n    Running setup.py install for default-user-module-name: started\n    Running setup.py install for default-user-module-name: finished with status 'done'\u001b[0m\n\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\u001b[0m\n\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n\u001b[34m2020-05-26 15:52:16,088 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n\u001b[34m2020-05-26 15:52:16,106 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n\u001b[34m2020-05-26 15:52:16,123 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n\u001b[34m2020-05-26 15:52:16,138 sagemaker-containers INFO     Invoking user script\n\u001b[0m\n\u001b[34mTraining Env:\n\u001b[0m\n\u001b[34m{\n    \"additional_framework_parameters\": {},\n    \"channel_input_dirs\": {\n        \"test\": \"/opt/ml/input/data/test\",\n        \"train\": \"/opt/ml/input/data/train\"\n    },\n    \"current_host\": \"algo-1\",\n    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n    \"hosts\": [\n        \"algo-1\"\n    ],\n    \"hyperparameters\": {\n        \"learning-rate\": 0.1\n    },\n    \"input_config_dir\": \"/opt/ml/input/config\",\n    \"input_data_config\": {\n        \"test\": {\n            \"TrainingInputMode\": \"File\",\n            \"S3DistributionType\": \"FullyReplicated\",\n            \"RecordWrapperType\": \"None\"\n        },\n        \"train\": {\n            \"TrainingInputMode\": \"File\",\n            \"S3DistributionType\": \"FullyReplicated\",\n            \"RecordWrapperType\": \"None\"\n        }\n    },\n    \"input_dir\": \"/opt/ml/input\",\n    \"is_master\": true,\n    \"job_name\": \"mxnet-training-2020-05-26-15-49-42-296\",\n    \"log_level\": 20,\n    \"master_hostname\": \"algo-1\",\n    \"model_dir\": \"/opt/ml/model\",\n    \"module_dir\": \"s3://md-backup-bucket-01/mxnet-mnist-example/code/mxnet-training-2020-05-26-15-49-42-296/source/sourcedir.tar.gz\",\n    \"module_name\": \"mnist\",\n    \"network_interface_name\": \"eth0\",\n    \"num_cpus\": 4,\n    \"num_gpus\": 0,\n    \"output_data_dir\": \"/opt/ml/output/data\",\n    \"output_dir\": \"/opt/ml/output\",\n    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n    \"resource_config\": {\n        \"current_host\": \"algo-1\",\n        \"hosts\": [\n            \"algo-1\"\n        ],\n        \"network_interface_name\": \"eth0\"\n    },\n    \"user_entry_point\": \"mnist.py\"\u001b[0m\n\u001b[34m}\n\u001b[0m\n\u001b[34mEnvironment variables:\n\u001b[0m\n\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n\u001b[34mSM_HPS={\"learning-rate\":0.1}\u001b[0m\n\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n\u001b[34mSM_NUM_CPUS=4\u001b[0m\n\u001b[34mSM_NUM_GPUS=0\u001b[0m\n\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n\u001b[34mSM_MODULE_DIR=s3://md-backup-bucket-01/mxnet-mnist-example/code/mxnet-training-2020-05-26-15-49-42-296/source/sourcedir.tar.gz\u001b[0m\n\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"learning-rate\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-05-26-15-49-42-296\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://md-backup-bucket-01/mxnet-mnist-example/code/mxnet-training-2020-05-26-15-49-42-296/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n\u001b[34mSM_USER_ARGS=[\"--learning-rate\",\"0.1\"]\u001b[0m\n\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n\u001b[34mSM_HP_LEARNING-RATE=0.1\u001b[0m\n\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n\u001b[0m\n\u001b[34mInvoking script with the following command:\n\u001b[0m\n\u001b[34m/usr/local/bin/python3.6 mnist.py --learning-rate 0.1\n\n\u001b[0m\n\u001b[34m[15:52:19] src/executor/graph_executor.cc:1984: Subgraph backend MKLDNN is activated.\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Batch [0-100]#011Speed: 45251.51 samples/sec#011accuracy=0.109505\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Batch [100-200]#011Speed: 44649.18 samples/sec#011accuracy=0.116200\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Batch [200-300]#011Speed: 39424.19 samples/sec#011accuracy=0.112600\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Batch [300-400]#011Speed: 44467.13 samples/sec#011accuracy=0.111500\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Batch [400-500]#011Speed: 37258.49 samples/sec#011accuracy=0.113800\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Train-accuracy=0.138483\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Time cost=1.468\u001b[0m\n\u001b[34mINFO:root:Epoch[0] Validation-accuracy=0.374500\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Batch [0-100]#011Speed: 42896.28 samples/sec#011accuracy=0.474455\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Batch [100-200]#011Speed: 40673.58 samples/sec#011accuracy=0.675600\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Batch [200-300]#011Speed: 44422.39 samples/sec#011accuracy=0.772800\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Batch [300-400]#011Speed: 43536.11 samples/sec#011accuracy=0.800100\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Batch [400-500]#011Speed: 44544.39 samples/sec#011accuracy=0.826900\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Train-accuracy=0.731733\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Time cost=1.385\u001b[0m\n\u001b[34mINFO:root:Epoch[1] Validation-accuracy=0.864300\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Batch [0-100]#011Speed: 37265.64 samples/sec#011accuracy=0.859703\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Batch [100-200]#011Speed: 38590.60 samples/sec#011accuracy=0.873300\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Batch [200-300]#011Speed: 45265.92 samples/sec#011accuracy=0.882900\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Batch [300-400]#011Speed: 47166.02 samples/sec#011accuracy=0.895700\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Batch [400-500]#011Speed: 46240.19 samples/sec#011accuracy=0.905100\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Train-accuracy=0.888383\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Time cost=1.410\u001b[0m\n\u001b[34mINFO:root:Epoch[2] Validation-accuracy=0.908700\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Batch [0-100]#011Speed: 46019.39 samples/sec#011accuracy=0.917030\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Batch [100-200]#011Speed: 43988.97 samples/sec#011accuracy=0.925800\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Batch [200-300]#011Speed: 39218.75 samples/sec#011accuracy=0.925300\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Batch [300-400]#011Speed: 39627.11 samples/sec#011accuracy=0.936900\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Batch [400-500]#011Speed: 44566.68 samples/sec#011accuracy=0.936800\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Train-accuracy=0.930100\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Time cost=1.415\u001b[0m\n\u001b[34mINFO:root:Epoch[3] Validation-accuracy=0.936400\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Batch [0-100]#011Speed: 45894.76 samples/sec#011accuracy=0.945842\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Batch [100-200]#011Speed: 43152.34 samples/sec#011accuracy=0.940800\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Batch [200-300]#011Speed: 43649.61 samples/sec#011accuracy=0.948600\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Batch [300-400]#011Speed: 42360.72 samples/sec#011accuracy=0.947600\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Batch [400-500]#011Speed: 42784.44 samples/sec#011accuracy=0.946100\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Train-accuracy=0.946617\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Time cost=1.408\u001b[0m\n\u001b[34mINFO:root:Epoch[4] Validation-accuracy=0.949900\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Batch [0-100]#011Speed: 41354.20 samples/sec#011accuracy=0.956337\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Batch [100-200]#011Speed: 41811.25 samples/sec#011accuracy=0.957100\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Batch [200-300]#011Speed: 42764.11 samples/sec#011accuracy=0.955600\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Batch [300-400]#011Speed: 42581.12 samples/sec#011accuracy=0.955600\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Batch [400-500]#011Speed: 44639.20 samples/sec#011accuracy=0.961400\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Train-accuracy=0.957567\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Time cost=1.431\u001b[0m\n\u001b[34mINFO:root:Epoch[5] Validation-accuracy=0.957300\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Batch [0-100]#011Speed: 40176.83 samples/sec#011accuracy=0.961683\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Batch [100-200]#011Speed: 45732.53 samples/sec#011accuracy=0.964900\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Batch [200-300]#011Speed: 47142.05 samples/sec#011accuracy=0.962000\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Batch [300-400]#011Speed: 45307.87 samples/sec#011accuracy=0.965000\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Batch [400-500]#011Speed: 42779.42 samples/sec#011accuracy=0.965500\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Train-accuracy=0.963533\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Time cost=1.374\u001b[0m\n\u001b[34mINFO:root:Epoch[6] Validation-accuracy=0.962200\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Batch [0-100]#011Speed: 40752.22 samples/sec#011accuracy=0.969307\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Batch [100-200]#011Speed: 43529.16 samples/sec#011accuracy=0.968700\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Batch [200-300]#011Speed: 44751.13 samples/sec#011accuracy=0.970000\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Batch [300-400]#011Speed: 43189.53 samples/sec#011accuracy=0.968500\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Batch [400-500]#011Speed: 45407.84 samples/sec#011accuracy=0.968200\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Train-accuracy=0.969217\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Time cost=1.390\u001b[0m\n\u001b[34mINFO:root:Epoch[7] Validation-accuracy=0.964400\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Batch [0-100]#011Speed: 45204.45 samples/sec#011accuracy=0.972277\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Batch [100-200]#011Speed: 35485.68 samples/sec#011accuracy=0.973700\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Batch [200-300]#011Speed: 36886.52 samples/sec#011accuracy=0.974100\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Batch [300-400]#011Speed: 34958.56 samples/sec#011accuracy=0.968100\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Batch [400-500]#011Speed: 44939.52 samples/sec#011accuracy=0.975600\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Train-accuracy=0.972950\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Time cost=1.514\u001b[0m\n\u001b[34mINFO:root:Epoch[8] Validation-accuracy=0.969200\u001b[0m\n\n2020-05-26 15:52:45 Uploading - Uploading generated training model\n2020-05-26 15:52:45 Completed - Training job completed\n\u001b[34mINFO:root:Epoch[9] Batch [0-100]#011Speed: 46324.25 samples/sec#011accuracy=0.976931\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Batch [100-200]#011Speed: 44289.92 samples/sec#011accuracy=0.978000\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Batch [200-300]#011Speed: 45108.68 samples/sec#011accuracy=0.974700\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Batch [300-400]#011Speed: 44689.19 samples/sec#011accuracy=0.977100\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Batch [400-500]#011Speed: 45451.58 samples/sec#011accuracy=0.972500\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Train-accuracy=0.976067\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Time cost=1.335\u001b[0m\n\u001b[34mINFO:root:Epoch[9] Validation-accuracy=0.970300\u001b[0m\n\u001b[34m2020-05-26 15:52:36,280 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\nTraining seconds: 72\nBillable seconds: 72\nCPU times: user 478 ms, sys: 84.7 ms, total: 563 ms\nWall time: 3min 18s\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data_location = 's3://{}/mxnet/mnist/train'.format(sample_data_bucket)\n",
    "test_data_location = 's3://{}/mxnet/mnist/test'.format(sample_data_bucket)\n",
    "\n",
    "mnist_estimator.fit({'train': train_data_location, 'test': test_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker's transformer class\n",
    "\n",
    "### After training, we use our `MXNet` estimator object to create a `Transformer` by invoking the `transformer()` method. This method takes arguments for configuring our options with the batch transform job; these do not need to be the same values as the one we used for the training job. The method also creates a SageMaker Model to be used for the batch transform jobs.\n",
    "\n",
    "### The `Transformer` class is responsible for running batch transform jobs, which deploys the trained model to an endpoint and send requests for performing inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = mnist_estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a batch transform job\n",
    "\n",
    "Now we can perform some inference with the model we've trained by running a batch transform job. The request handling behavior during the transform job is determined by the `mnist.py` script.\n",
    "\n",
    "For demonstration purposes, we're going to use input data that contains 1000 MNIST images, located in the public SageMaker sample data S3 bucket. To create the batch transform job, we simply call `transform()` on our transformer with information about the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadBucket operation: Not Found",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mdefault_bucket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 s3.create_bucket(\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCreateBucketConfiguration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"LocationConstraint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/boto3/resources/factory.py\u001b[0m in \u001b[0;36mdo_action\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdo_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/boto3/resources/action.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parent, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (TooManyBuckets) when calling the CreateBucket operation: You have attempted to create more buckets than allowed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ac734b185e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'batch-transform/mnist-1000-samples'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3://{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_data_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text/csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, wait, logs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_output_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             self.output_path = \"s3://{}/{}\".format(\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             )\n\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_output_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mdefault_bucket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"TooManyBuckets\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# Succeed if the default bucket exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_bucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (404) when calling the HeadBucket operation: Not Found"
     ]
    }
   ],
   "source": [
    "input_file_path = 'batch-transform/mnist-1000-samples'\n",
    "\n",
    "transformer.transform('s3://{}/{}'.format(sample_data_bucket, input_file_path), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wait for the batch transform job to complete. We have a convenience method, `wait()`, that blocks until the batch transform job has completed. We call that here to see if the batch transform job is still running; the cell finishes running when the batch transform job has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the results\n",
    "\n",
    "The batch transform job uploads its predictions to S3. Since we did not specify `output_path` when creating the Transformer, one was generated based on the batch transform job name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output here will be a list of predictions, where each prediction is a list of probabilities, one for each possible label. Since we read the output as a string, we use `ast.literal_eval()` to turn it into a list and find the maximum element of the list gives us the predicted label. Here we define a convenience method to take the output and produce the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def predicted_label(transform_output):\n",
    "    output = ast.literal_eval(transform_output)\n",
    "    probabilities = output[0]\n",
    "    return probabilities.index(max(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the first ten results from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    file_key = '{}/data-{}.csv.out'.format(transformer.output_path, i)\n",
    "    output = S3Downloader.read_file(file_key)\n",
    "\n",
    "    predictions.append(predicted_label(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we also download and display the corresponding original input data so that we can see how the model did with its predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (2,10)\n",
    "\n",
    "def show_digit(img, caption='', subplot=None):\n",
    "    if subplot == None:\n",
    "        _,(subplot) = plt.subplots(1,1)\n",
    "    imgr = img.reshape((28,28))\n",
    "    subplot.axis('off')\n",
    "    subplot.imshow(imgr, cmap='gray')\n",
    "    plt.title(caption)\n",
    "\n",
    "for i in range(10):\n",
    "    input_file_name = 'data-{}.csv'.format(i)\n",
    "    input_file_uri = 's3://{}/{}/{}'.format(sample_data_bucket, input_file_path, input_file_name)\n",
    "\n",
    "    input_data = np.fromstring(S3Downloader.read_file(input_file_uri), sep=',')\n",
    "    show_digit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Here, we can see the original labels are:\n",
    "\n",
    "```\n",
    "7, 2, 1, 0, 4, 1, 4, 9, 5, 9\n",
    "```\n",
    "\n",
    "Now let's print out the predictions to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "notice": "Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}