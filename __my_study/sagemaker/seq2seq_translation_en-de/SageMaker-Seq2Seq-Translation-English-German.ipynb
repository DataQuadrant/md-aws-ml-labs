{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation English-German Example Using SageMaker Seq2Seq\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Download dataset and preprocess](#Download-dataset-and-preprocess)\n",
    "3. [Training the Machine Translation model](#Training-the-Machine-Translation-model)\n",
    "4. [Inference](#Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to our Machine Translation end-to-end example! In this demo, we will train a English-German translation model and will test the predictions on a few examples.\n",
    "\n",
    "SageMaker Seq2Seq algorithm is built on top of [Sockeye](https://github.com/awslabs/sockeye), a sequence-to-sequence framework for Neural Machine Translation based on MXNet. SageMaker Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "- The S3 bucket and prefix that you want to use for training and model data. **This should be within the same region as the Notebook Instance, training, and hosting.**\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp in the cell below with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# S3 bucket and prefix\n",
    "bucket = 'md-backup-bucket-01'\n",
    "prefix = 'sagemaker/DEMO-seq2seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# role = get_execution_role()\n",
    "role = 'arn:aws:iam::558157414092:role/service-role/AmazonSageMaker-ExecutionRole-20200523T082014'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# For plotting attention matrix later on\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will train a English to German translation model on a dataset from the\n",
    "[Conference on Machine Translation (WMT) 2017](http://www.statmt.org/wmt17/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "K .......... .......... .......... .......... .......... 95% 1.99M 6s\n279800K .......... .......... .......... .......... .......... 95% 1.35M 6s\n279850K .......... .......... .......... .......... .......... 95% 2.08M 6s\n279900K .......... .......... .......... .......... .......... 95% 1.96M 6s\n279950K .......... .......... .......... .......... .......... 95% 2.52M 6s\n280000K .......... .......... .......... .......... .......... 95% 1.61M 6s\n280050K .......... .......... .......... .......... .......... 95% 1.71M 6s\n280100K .......... .......... .......... .......... .......... 95% 2.02M 6s\n280150K .......... .......... .......... .......... .......... 95% 1.57M 6s\n280200K .......... .......... .......... .......... .......... 95% 2.95M 6s\n280250K .......... .......... .......... .......... .......... 95% 2.15M 6s\n280300K .......... .......... .......... .......... .......... 95% 1.59M 6s\n280350K .......... .......... .......... .......... .......... 95% 1.19M 6s\n280400K .......... .......... .......... .......... .......... 95% 2.11M 6s\n280450K .......... .......... .......... .......... .......... 95% 2.68M 6s\n280500K .......... .......... .......... .......... .......... 95% 1.51M 6s\n280550K .......... .......... .......... .......... .......... 95% 2.02M 6s\n280600K .......... .......... .......... .......... .......... 95% 1.35M 6s\n280650K .......... .......... .......... .......... .......... 95% 1.58M 6s\n280700K .......... .......... .......... .......... .......... 95% 2.71M 6s\n280750K .......... .......... .......... .......... .......... 95% 1.63M 6s\n280800K .......... .......... .......... .......... .......... 95% 1.72M 6s\n280850K .......... .......... .......... .......... .......... 95% 1.31M 6s\n280900K .......... .......... .......... .......... .......... 95% 2.43M 5s\n280950K .......... .......... .......... .......... .......... 96% 2.09M 5s\n281000K .......... .......... .......... .......... .......... 96% 1.98M 5s\n281050K .......... .......... .......... .......... .......... 96% 1.66M 5s\n281100K .......... .......... .......... .......... .......... 96% 1.52M 5s\n281150K .......... .......... .......... .......... .......... 96% 1.69M 5s\n281200K .......... .......... .......... .......... .......... 96% 1.70M 5s\n281250K .......... .......... .......... .......... .......... 96% 1.96M 5s\n281300K .......... .......... .......... .......... .......... 96% 4.01M 5s\n281350K .......... .......... .......... .......... .......... 96% 1.59M 5s\n281400K .......... .......... .......... .......... .......... 96% 1.56M 5s\n281450K .......... .......... .......... .......... .......... 96% 2.05M 5s\n281500K .......... .......... .......... .......... .......... 96% 1.68M 5s\n281550K .......... .......... .......... .......... .......... 96% 3.92M 5s\n281600K .......... .......... .......... .......... .......... 96% 1.71M 5s\n281650K .......... .......... .......... .......... .......... 96% 1.40M 5s\n281700K .......... .......... .......... .......... .......... 96% 2.51M 5s\n281750K .......... .......... .......... .......... .......... 96% 1.56M 5s\n281800K .......... .......... .......... .......... .......... 96% 3.04M 5s\n281850K .......... .......... .......... .......... .......... 96% 1.77M 5s\n281900K .......... .......... .......... .......... .......... 96% 1.29M 5s\n281950K .......... .......... .......... .......... .......... 96% 3.67M 5s\n282000K .......... .......... .......... .......... .......... 96% 1.58M 5s\n282050K .......... .......... .......... .......... .......... 96% 2.81M 5s\n282100K .......... .......... .......... .......... .......... 96% 1.64M 5s\n282150K .......... .......... .......... .......... .......... 96% 1.49M 5s\n282200K .......... .......... .......... .......... .......... 96% 3.89M 5s\n282250K .......... .......... .......... .......... .......... 96% 1.39M 5s\n282300K .......... .......... .......... .......... .......... 96% 4.23M 5s\n282350K .......... .......... .......... .......... .......... 96% 1.34M 5s\n282400K .......... .......... .......... .......... .......... 96% 2.53M 5s\n282450K .......... .......... .......... .......... .......... 96% 1.90M 5s\n282500K .......... .......... .......... .......... .......... 96% 3.84M 5s\n282550K .......... .......... .......... .......... .......... 96% 1.45M 5s\n282600K .......... .......... .......... .......... .......... 96% 2.38M 5s\n282650K .......... .......... .......... .......... .......... 96% 1.27M 5s\n282700K .......... .......... .......... .......... .......... 96% 2.10M 5s\n282750K .......... .......... .......... .......... .......... 96% 3.61M 5s\n282800K .......... .......... .......... .......... .......... 96% 1.58M 5s\n282850K .......... .......... .......... .......... .......... 96% 2.37M 5s\n282900K .......... .......... .......... .......... .......... 96% 1.28M 5s\n282950K .......... .......... .......... .......... .......... 96% 3.50M 5s\n283000K .......... .......... .......... .......... .......... 96% 1.88M 5s\n283050K .......... .......... .......... .......... .......... 96% 1.46M 4s\n283100K .......... .......... .......... .......... .......... 96% 2.59M 4s\n283150K .......... .......... .......... .......... .......... 96% 2.13M 4s\n283200K .......... .......... .......... .......... .......... 96% 1.71M 4s\n283250K .......... .......... .......... .......... .......... 96% 2.00M 4s\n283300K .......... .......... .......... .......... .......... 96% 2.02M 4s\n283350K .......... .......... .......... .......... .......... 96% 1.80M 4s\n283400K .......... .......... .......... .......... .......... 96% 2.23M 4s\n283450K .......... .......... .......... .......... .......... 96% 2.17M 4s\n283500K .......... .......... .......... .......... .......... 96% 1.63M 4s\n283550K .......... .......... .......... .......... .......... 96% 3.39M 4s\n283600K .......... .......... .......... .......... .......... 96% 1.52M 4s\n283650K .......... .......... .......... .......... .......... 96% 2.71M 4s\n283700K .......... .......... .......... .......... .......... 96% 1.51M 4s\n283750K .......... .......... .......... .......... .......... 96% 1.78M 4s\n283800K .......... .......... .......... .......... .......... 96% 2.44M 4s\n283850K .......... .......... .......... .......... .......... 97% 1.90M 4s\n283900K .......... .......... .......... .......... .......... 97% 2.34M 4s\n283950K .......... .......... .......... .......... .......... 97% 1.35M 4s\n284000K .......... .......... .......... .......... .......... 97% 2.22M 4s\n284050K .......... .......... .......... .......... .......... 97% 2.11M 4s\n284100K .......... .......... .......... .......... .......... 97% 1.90M 4s\n284150K .......... .......... .......... .......... .......... 97% 3.09M 4s\n284200K .......... .......... .......... .......... .......... 97% 1.90M 4s\n284250K .......... .......... .......... .......... .......... 97% 1.18M 4s\n284300K .......... .......... .......... .......... .......... 97% 1.51M 4s\n284350K .......... .......... .......... .......... .......... 97% 2.20M 4s\n284400K .......... .......... .......... .......... .......... 97% 1.29M 4s\n284450K .......... .......... .......... .......... .......... 97% 1.31M 4s\n284500K .......... .......... .......... .......... .......... 97% 1.84M 4s\n284550K .......... .......... .......... .......... .......... 97%  949K 4s\n284600K .......... .......... .......... .......... .......... 97% 2.07M 4s\n284650K .......... .......... .......... .......... .......... 97% 1.39M 4s\n284700K .......... .......... .......... .......... .......... 97% 1.79M 4s\n284750K .......... .......... .......... .......... .......... 97% 2.73M 4s\n284800K .......... .......... .......... .......... .......... 97% 1.31M 4s\n284850K .......... .......... .......... .......... .......... 97% 6.21M 4s\n284900K .......... .......... .......... .......... .......... 97% 2.24M 4s\n284950K .......... .......... .......... .......... .......... 97% 1015K 4s\n285000K .......... .......... .......... .......... .......... 97% 4.33M 4s\n285050K .......... .......... .......... .......... .......... 97% 2.17M 4s\n285100K .......... .......... .......... .......... .......... 97% 1.79M 4s\n285150K .......... .......... .......... .......... .......... 97% 3.16M 4s\n285200K .......... .......... .......... .......... .......... 97% 1.18M 3s\n285250K .......... .......... .......... .......... .......... 97% 1.99M 3s\n285300K .......... .......... .......... .......... .......... 97% 2.59M 3s\n285350K .......... .......... .......... .......... .......... 97% 1.56M 3s\n285400K .......... .......... .......... .......... .......... 97% 4.10M 3s\n285450K .......... .......... .......... .......... .......... 97% 1.48M 3s\n285500K .......... .......... .......... .......... .......... 97% 1.35M 3s\n285550K .......... .......... .......... .......... .......... 97% 4.82M 3s\n285600K .......... .......... .......... .......... .......... 97% 1.21M 3s\n285650K .......... .......... .......... .......... .......... 97% 4.97M 3s\n285700K .......... .......... .......... .......... .......... 97% 2.88M 3s\n285750K .......... .......... .......... .......... .......... 97% 1.06M 3s\n285800K .......... .......... .......... .......... .......... 97% 2.46M 3s\n285850K .......... .......... .......... .......... .......... 97% 1.32M 3s\n285900K .......... .......... .......... .......... .......... 97% 3.95M 3s\n285950K .......... .......... .......... .......... .......... 97% 4.45M 3s\n286000K .......... .......... .......... .......... .......... 97% 1.08M 3s\n286050K .......... .......... .......... .......... .......... 97% 1.88M 3s\n286100K .......... .......... .......... .......... .......... 97% 2.12M 3s\n286150K .......... .......... .......... .......... .......... 97% 1.88M 3s\n286200K .......... .......... .......... .......... .......... 97% 3.74M 3s\n286250K .......... .......... .......... .......... .......... 97% 2.63M 3s\n286300K .......... .......... .......... .......... .......... 97% 1.11M 3s\n286350K .......... .......... .......... .......... .......... 97% 2.71M 3s\n286400K .......... .......... .......... .......... .......... 97% 1.58M 3s\n286450K .......... .......... .......... .......... .......... 97% 2.45M 3s\n286500K .......... .......... .......... .......... .......... 97% 5.04M 3s\n286550K .......... .......... .......... .......... .......... 97% 1.22M 3s\n286600K .......... .......... .......... .......... .......... 97% 1.64M 3s\n286650K .......... .......... .......... .......... .......... 97% 1.71M 3s\n286700K .......... .......... .......... .......... .......... 97% 2.82M 3s\n286750K .......... .......... .......... .......... .......... 97% 2.81M 3s\n286800K .......... .......... .......... .......... .......... 98% 1.58M 3s\n286850K .......... .......... .......... .......... .......... 98% 1.28M 3s\n286900K .......... .......... .......... .......... .......... 98% 2.76M 3s\n286950K .......... .......... .......... .......... .......... 98% 2.19M 3s\n287000K .......... .......... .......... .......... .......... 98% 2.66M 3s\n287050K .......... .......... .......... .......... .......... 98% 2.65M 3s\n287100K .......... .......... .......... .......... .......... 98% 1.20M 3s\n287150K .......... .......... .......... .......... .......... 98% 2.31M 3s\n287200K .......... .......... .......... .......... .......... 98% 1.58M 3s\n287250K .......... .......... .......... .......... .......... 98% 2.72M 3s\n287300K .......... .......... .......... .......... .......... 98% 3.02M 2s\n287350K .......... .......... .......... .......... .......... 98% 1.52M 2s\n287400K .......... .......... .......... .......... .......... 98% 1.60M 2s\n287450K .......... .......... .......... .......... .......... 98% 1.78M 2s\n287500K .......... .......... .......... .......... .......... 98% 1.89M 2s\n287550K .......... .......... .......... .......... .......... 98% 4.27M 2s\n287600K .......... .......... .......... .......... .......... 98% 1.27M 2s\n287650K .......... .......... .......... .......... .......... 98% 2.26M 2s\n287700K .......... .......... .......... .......... .......... 98% 2.04M 2s\n287750K .......... .......... .......... .......... .......... 98% 1.63M 2s\n287800K .......... .......... .......... .......... .......... 98% 2.74M 2s\n287850K .......... .......... .......... .......... .......... 98% 2.53M 2s\n287900K .......... .......... .......... .......... .......... 98% 1.34M 2s\n287950K .......... .......... .......... .......... .......... 98% 3.11M 2s\n288000K .......... .......... .......... .......... .......... 98% 1.46M 2s\n288050K .......... .......... .......... .......... .......... 98% 1.98M 2s\n288100K .......... .......... .......... .......... .......... 98% 3.39M 2s\n288150K .......... .......... .......... .......... .......... 98% 1.29M 2s\n288200K .......... .......... .......... .......... .......... 98% 3.51M 2s\n288250K .......... .......... .......... .......... .......... 98% 1.50M 2s\n288300K .......... .......... .......... .......... .......... 98% 2.21M 2s\n288350K .......... .......... .......... .......... .......... 98% 1.27M 2s\n288400K .......... .......... .......... .......... .......... 98% 2.51M 2s\n288450K .......... .......... .......... .......... .......... 98% 2.70M 2s\n288500K .......... .......... .......... .......... .......... 98% 2.47M 2s\n288550K .......... .......... .......... .......... .......... 98% 1.33M 2s\n288600K .......... .......... .......... .......... .......... 98% 2.51M 2s\n288650K .......... .......... .......... .......... .......... 98% 1.85M 2s\n288700K .......... .......... .......... .......... .......... 98% 1.91M 2s\n288750K .......... .......... .......... .......... .......... 98% 3.84M 2s\n288800K .......... .......... .......... .......... .......... 98% 1.07M 2s\n288850K .......... .......... .......... .......... .......... 98% 3.79M 2s\n288900K .......... .......... .......... .......... .......... 98% 1.25M 2s\n288950K .......... .......... .......... .......... .......... 98% 3.67M 2s\n289000K .......... .......... .......... .......... .......... 98% 2.34M 2s\n289050K .......... .......... .......... .......... .......... 98% 1.85M 2s\n289100K .......... .......... .......... .......... .......... 98% 1.83M 2s\n289150K .......... .......... .......... .......... .......... 98% 1.28M 2s\n289200K .......... .......... .......... .......... .......... 98% 2.79M 2s\n289250K .......... .......... .......... .......... .......... 98% 3.01M 2s\n289300K .......... .......... .......... .......... .......... 98% 2.51M 2s\n289350K .......... .......... .......... .......... .......... 98% 1.25M 2s\n289400K .......... .......... .......... .......... .......... 98% 1.53M 2s\n289450K .......... .......... .......... .......... .......... 98% 2.39M 1s\n289500K .......... .......... .......... .......... .......... 98% 3.35M 1s\n289550K .......... .......... .......... .......... .......... 98% 3.67M 1s\n289600K .......... .......... .......... .......... .......... 98% 1.19M 1s\n289650K .......... .......... .......... .......... .......... 98% 3.04M 1s\n289700K .......... .......... .......... .......... .......... 99% 1.11M 1s\n289750K .......... .......... .......... .......... .......... 99% 3.06M 1s\n289800K .......... .......... .......... .......... .......... 99% 4.03M 1s\n289850K .......... .......... .......... .......... .......... 99% 2.16M 1s\n289900K .......... .......... .......... .......... .......... 99% 1.46M 1s\n289950K .......... .......... .......... .......... .......... 99% 1.43M 1s\n290000K .......... .......... .......... .......... .......... 99% 1.92M 1s\n290050K .......... .......... .......... .......... .......... 99% 2.98M 1s\n290100K .......... .......... .......... .......... .......... 99% 3.50M 1s\n290150K .......... .......... .......... .......... .......... 99% 1.55M 1s\n290200K .......... .......... .......... .......... .......... 99% 3.26M 1s\n290250K .......... .......... .......... .......... .......... 99% 1.16M 1s\n290300K .......... .......... .......... .......... .......... 99% 2.22M 1s\n290350K .......... .......... .......... .......... .......... 99% 2.93M 1s\n290400K .......... .......... .......... .......... .......... 99% 3.75M 1s\n290450K .......... .......... .......... .......... .......... 99% 1.64M 1s\n290500K .......... .......... .......... .......... .......... 99% 1.19M 1s\n290550K .......... .......... .......... .......... .......... 99% 1.59M 1s\n290600K .......... .......... .......... .......... .......... 99% 8.71M 1s\n290650K .......... .......... .......... .......... .......... 99% 2.43M 1s\n290700K .......... .......... .......... .......... .......... 99% 1.73M 1s\n290750K .......... .......... .......... .......... .......... 99% 2.78M 1s\n290800K .......... .......... .......... .......... .......... 99% 1.42M 1s\n290850K .......... .......... .......... .......... .......... 99% 1.83M 1s\n290900K .......... .......... .......... .......... .......... 99% 3.34M 1s\n290950K .......... .......... .......... .......... .......... 99% 1.75M 1s\n291000K .......... .......... .......... .......... .......... 99% 2.70M 1s\n291050K .......... .......... .......... .......... .......... 99% 1.21M 1s\n291100K .......... .......... .......... .......... .......... 99% 2.04M 1s\n291150K .......... .......... .......... .......... .......... 99% 3.92M 1s\n291200K .......... .......... .......... .......... .......... 99% 2.65M 1s\n291250K .......... .......... .......... .......... .......... 99% 1.89M 1s\n291300K .......... .......... .......... .......... .......... 99% 2.25M 1s\n291350K .......... .......... .......... .......... .......... 99% 1.26M 1s\n291400K .......... .......... .......... .......... .......... 99% 2.48M 1s\n291450K .......... .......... .......... .......... .......... 99% 3.04M 1s\n291500K .......... .......... .......... .......... .......... 99% 1.87M 1s\n291550K .......... .......... .......... .......... .......... 99% 3.60M 0s\n291600K .......... .......... .......... .......... .......... 99% 1.19M 0s\n291650K .......... .......... .......... .......... .......... 99% 2.21M 0s\n291700K .......... .......... .......... .......... .......... 99% 2.42M 0s\n291750K .......... .......... .......... .......... .......... 99% 3.34M 0s\n291800K .......... .......... .......... .......... .......... 99% 1.81M 0s\n291850K .......... .......... .......... .......... .......... 99% 2.60M 0s\n291900K .......... .......... .......... .......... .......... 99% 1.10M 0s\n291950K .......... .......... .......... .......... .......... 99% 3.50M 0s\n292000K .......... .......... .......... .......... .......... 99% 2.02M 0s\n292050K .......... .......... .......... .......... .......... 99% 2.37M 0s\n292100K .......... .......... .......... .......... .......... 99% 2.70M 0s\n292150K .......... .......... .......... .......... .......... 99% 1.32M 0s\n292200K .......... .......... .......... .......... .......... 99% 1.82M 0s\n292250K .......... .......... .......... .......... .......... 99% 1.98M 0s\n292300K .......... .......... .......... .......... .......... 99% 3.12M 0s\n292350K .......... .......... .......... .......... .......... 99% 3.37M 0s\n292400K .......... .......... .......... .......... .......... 99% 1.14M 0s\n292450K .......... .......... .......... .......... .......... 99% 2.17M 0s\n292500K .......... .......... .......... .......... .......... 99% 3.72M 0s\n292550K .......... .......... .......... .......... .......... 99% 1.53M 0s\n292600K .......... .......... .......... .......... .......... 99% 5.99M 0s\n292650K .......                                               100% 3.41M=2m18s\n\n2020-05-27 19:29:28 (2.08 MB/s) - ‘corpus.tc.de.gz’ saved [299680879/299680879]\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 2413k  100 2413k    0     0  1137k      0  0:00:02  0:00:02 --:--:-- 1137k\n"
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/corpus.tc.de.gz & \\\n",
    "wget http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/corpus.tc.en.gz & wait\n",
    "gunzip corpus.tc.de.gz & \\\n",
    "gunzip corpus.tc.en.gz & wait\n",
    "mkdir validation\n",
    "curl http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/dev.tgz | tar xvzf - -C validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that it is a common practise to split words into subwords using Byte Pair Encoding (BPE). Please refer to [this](https://github.com/awslabs/sockeye/tree/master/tutorials/wmt) tutorial if you are interested in performing BPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training on the whole dataset might take several hours/days, for this demo, let us train on the **first 10,000 lines only**. Don't run the next cell if you want to train on the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head -n 10000 corpus.tc.en > corpus.tc.en.small\n",
    "!head -n 10000 corpus.tc.de > corpus.tc.de.small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the preprocessing script `create_vocab_proto.py` (provided with this notebook) to create vocabulary mappings (strings to integers) and convert these files to x-recordio-protobuf as required for training by SageMaker Seq2Seq.  \n",
    "Uncomment the cell below and run to see check the arguments this script expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/ec2-user/anaconda3/bin/python\n"
    }
   ],
   "source": [
    "%%bash\n",
    "# python3 create_vocab_proto.py -h\n",
    "which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below does the preprocessing. If you are using the complete dataset, the script might take around 10-15 min on an m4.xlarge notebook instance. Remove \".small\" from the file names for training on full datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[31mERROR: Could not find a version that satisfies the requirement record_pb2 (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for record_pb2\u001b[0m\n"
    }
   ],
   "source": [
    "import sys\n",
    "! {sys.prefix}/bin/pip install record_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/home/ec2-user/anaconda3/envs/python3'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:__main__:Building vocabulary from dataset: corpus.tc.en.small and corpus.tc.de.small\nINFO:__main__:Final vocabulary: 10661 types (min frequency 1, top 50000 types)\nINFO:__main__:Final vocabulary: 15980 types (min frequency 1, top 50000 types)\nINFO:__main__:Source vocabulary size: 10661 \nINFO:__main__:Vocabulary saved to \"vocab.src.json\"\nINFO:__main__:Target vocabulary size: 15980 \nINFO:__main__:Vocabulary saved to \"vocab.trg.json\"\nINFO:__main__:Spawning 7 encoding worker(s) for encoding train datasets!\nINFO:__main__:Processed 10000 lines for encoding to protobuf. 0 lines were ignored as they didn't have\n                any content in either the source or the target file!\nINFO:__main__:Completed writing the encoding queue!\nINFO:__main__:Encoding finished! Writing records to \"train.rec\"\nINFO:__main__:Processed input and saved to \"train.rec\"\nINFO:__main__:Spawning 7 encoding worker(s) for encoding validation datasets!\nINFO:__main__:Processed 3003 lines for encoding to protobuf. 0 lines were ignored as they didn't have\n                any content in either the source or the target file!\nINFO:__main__:Completed writing the encoding queue!\nINFO:__main__:Encoding finished! Writing records to \"val.rec\"\nINFO:__main__:Processed input and saved to \"val.rec\"\n"
    }
   ],
   "source": [
    "import sys\n",
    "# %%time\n",
    "# %%bash\n",
    "\n",
    "! {sys.prefix}/bin/python create_vocab_proto.py  --train-source corpus.tc.en.small --train-target corpus.tc.de.small  --val-source validation/newstest2014.tc.en --val-target validation/newstest2014.tc.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will output 4 files, namely:\n",
    "- train.rec : Contains source and target sentences for training in protobuf format\n",
    "- val.rec : Contains source and target sentences for validation in protobuf format\n",
    "- vocab.src.json : Vocabulary mapping (string to int) for source language (English in this example)\n",
    "- vocab.trg.json : Vocabulary mapping (string to int) for target language (German in this example)\n",
    "\n",
    "Let's upload the pre-processed dataset and vocabularies to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upload_to_s3(bucket, prefix, channel, file):\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, \"rb\")\n",
    "    key = prefix + \"/\" + channel + '/' + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "upload_to_s3(bucket, prefix, 'train', 'train.rec')\n",
    "upload_to_s3(bucket, prefix, 'validation', 'val.rec')\n",
    "upload_to_s3(bucket, prefix, 'vocab', 'vocab.src.json')\n",
    "upload_to_s3(bucket, prefix, 'vocab', 'vocab.trg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using SageMaker Seq2Seq container: 825641698319.dkr.ecr.us-east-2.amazonaws.com/seq2seq:1 (us-east-2)\n"
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region_name, 'seq2seq')\n",
    "\n",
    "print('Using SageMaker Seq2Seq container: {} ({})'.format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Machine Translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training job seq2seq-en-de-2020-05-27-19\nInProgress\n"
    }
   ],
   "source": [
    "job_name = 'seq2seq-en-de-' + strftime(\"%Y-%m-%d-%H\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": \"s3://{}/{}/\".format(bucket, prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        # Seq2Seq does not support multiple machines. Currently, it only supports single machine, multiple GPUs\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.xlarge\", # We suggest one of [\"ml.p2.16xlarge\", \"ml.p2.8xlarge\", \"ml.p2.xlarge\"]\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        # Please refer to the documentation for complete list of parameters\n",
    "        \"max_seq_len_source\": \"60\",\n",
    "        \"max_seq_len_target\": \"60\",\n",
    "        \"optimized_metric\": \"bleu\",\n",
    "        \"batch_size\": \"64\", # Please use a larger batch size (256 or 512) if using ml.p2.8xlarge or ml.p2.16xlarge\n",
    "        \"checkpoint_frequency_num_batches\": \"1000\",\n",
    "        \"rnn_num_hidden\": \"512\",\n",
    "        \"num_layers_encoder\": \"1\",\n",
    "        \"num_layers_decoder\": \"1\",\n",
    "        \"num_embed_source\": \"512\",\n",
    "        \"num_embed_target\": \"512\",\n",
    "        \"checkpoint_threshold\": \"3\",\n",
    "        \"max_num_batches\": \"2100\"\n",
    "        # Training will stop after 2100 iterations/batches.\n",
    "        # This is just for demo purposes. Remove the above parameter if you want a better model.\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 48 * 3600\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"vocab\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/vocab/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker_client = boto3.Session().client(service_name='sagemaker')\n",
    "sagemaker_client.create_training_job(**create_training_params)\n",
    "\n",
    "status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "InProgress\n"
    }
   ],
   "source": [
    "status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the job failed, determine why\n",
    "if status == 'Failed':\n",
    "    message = sagemaker_client.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))\n",
    "    raise Exception('Training job failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now wait for the training job to complete and proceed to the next step after you see model artifacts in your S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can jump to [Use a pretrained model](#Use-a-pretrained-model) as training might take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means translating sentence(s) from English to German.\n",
    "This section involves several steps,\n",
    "- Create model - Create a model using the artifact (model.tar.gz) produced by training\n",
    "- Create Endpoint Configuration - Create a configuration defining an endpoint, using the above model\n",
    "- Create Endpoint - Use the configuration to create an inference endpoint.\n",
    "- Perform Inference - Perform inference on some input data using the endpoint.\n",
    "\n",
    "### Create model\n",
    "We now create a SageMaker Model from the training output. Using the model, we can then create an Endpoint Configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_pretrained_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a pretrained model\n",
    "#### Please uncomment and run the cell below if you want to use a pretrained model, as training might take several hours/days to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  336M  100  336M    0     0  2865k      0  0:02:00  0:02:00 --:--:-- 4126k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   243    0   243    0     0    521      0 --:--:-- --:--:-- --:--:--   520\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   243    0   243    0     0    721      0 --:--:-- --:--:-- --:--:--   718\n"
    }
   ],
   "source": [
    "use_pretrained_model = True\n",
    "model_name = \"seq2seq-pretrained-en-de-model\"\n",
    "!curl https://s3-us-west-2.amazonaws.com/seq2seq-data/model.tar.gz > model.tar.gz\n",
    "!curl https://s3-us-west-2.amazonaws.com/seq2seq-data/vocab.src.json > vocab.src.json\n",
    "!curl https://s3-us-west-2.amazonaws.com/seq2seq-data/vocab.trg.json > vocab.trg.json\n",
    "upload_to_s3(bucket, prefix, 'pretrained_model', 'model.tar.gz')\n",
    "model_data = \"s3://{}/{}/pretrained_model/model.tar.gz\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "seq2seq-pretrained-en-de-model\ns3://md-backup-bucket-01/sagemaker/DEMO-seq2seq/pretrained_model/model.tar.gz\narn:aws:sagemaker:us-east-2:558157414092:model/seq2seq-pretrained-en-de-model\nCPU times: user 28.6 ms, sys: 3.31 ms, total: 31.9 ms\nWall time: 691 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sage = boto3.client('sagemaker')\n",
    "\n",
    "if not use_pretrained_model:\n",
    "    info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "    model_name=job_name\n",
    "    model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print(model_name)\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "Use the model to create an endpoint configuration. The endpoint configuration also contains information about the type and number of EC2 instances to use when hosting the model.\n",
    "\n",
    "Since SageMaker Seq2Seq is based on Neural Nets, we could use an ml.p2.xlarge (GPU) instance, but for this example we will use a free tier eligible ml.m4.xlarge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Seq2SeqEndpointConfig-2020-05-27-20-13-43\nEndpoint Config Arn: arn:aws:sagemaker:us-east-2:558157414092:endpoint-config/seq2seqendpointconfig-2020-05-27-20-13-43\n"
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'Seq2SeqEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, we create the endpoint that serves up model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 10-15 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Seq2SeqEndpoint-2020-05-27-20-14-04\narn:aws:sagemaker:us-east-2:558157414092:endpoint/seq2seqendpoint-2020-05-27-20-14-04\nStatus: Creating\nEndpoint creation ended with EndpointStatus = InService\nCPU times: user 271 ms, sys: 24.2 ms, total: 296 ms\nWall time: 7min 35s\n"
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'Seq2SeqEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sage.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "# wait until the status has changed\n",
    "sage.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "\n",
    "# print the status of the endpoint\n",
    "endpoint_response = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "print('Endpoint creation ended with EndpointStatus = {}'.format(status))\n",
    "\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message,\n",
    "> Endpoint creation ended with EndpointStatus = InService\n",
    "\n",
    "then congratulations! You now have a functioning inference endpoint. You can confirm the endpoint configuration and status by navigating to the \"Endpoints\" tab in the AWS SageMaker console.  \n",
    "\n",
    "We will finally create a runtime object from which we can invoke the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client(service_name='runtime.sagemaker') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using JSON format for inference (Suggested for a single or small number of data instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that you don't have to convert string to text using the vocabulary mapping for inference using JSON mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [\"you are so good !\",\n",
    "             \"can you drive a car ?\",\n",
    "             \"i want to watch a movie .\"\n",
    "            ]\n",
    "\n",
    "payload = {\"instances\" : []}\n",
    "for sent in sentences:\n",
    "    payload[\"instances\"].append({\"data\" : sent})\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the Attention Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `\"attention_matrix\":\"true\"` in `configuration` of the data instance will return the attention matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'can you drive a car ?'\n",
    "\n",
    "payload = {\"instances\" : [{\n",
    "                            \"data\" : sentence,\n",
    "                            \"configuration\" : {\"attention_matrix\":\"true\"}\n",
    "                          }\n",
    "                         ]}\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)['predictions'][0]\n",
    "\n",
    "source = sentence\n",
    "target = response[\"target\"]\n",
    "attention_matrix = np.array(response[\"matrix\"])\n",
    "\n",
    "print(\"Source: %s \\nTarget: %s\" % (source, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function for plotting the attentioan matrix\n",
    "def plot_matrix(attention_matrix, target, source):\n",
    "    source_tokens = source.split()\n",
    "    target_tokens = target.split()\n",
    "    assert attention_matrix.shape[0] == len(target_tokens)\n",
    "    plt.imshow(attention_matrix.transpose(), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.xlabel(\"target\")\n",
    "    plt.ylabel(\"source\")\n",
    "    plt.gca().set_xticks([i for i in range(0, len(target_tokens))])\n",
    "    plt.gca().set_yticks([i for i in range(0, len(source_tokens))])\n",
    "    plt.gca().set_xticklabels(target_tokens)\n",
    "    plt.gca().set_yticklabels(source_tokens)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_matrix(attention_matrix, target, source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Protobuf format for inference (Suggested for efficient bulk inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the vocabulary mappings as this mode of inference accepts list of integers and returns list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import tempfile\n",
    "from record_pb2 import Record\n",
    "from create_vocab_proto import vocab_from_json, reverse_vocab, write_recordio, list_to_record_bytes, read_next\n",
    "\n",
    "source = vocab_from_json(\"vocab.src.json\")\n",
    "target = vocab_from_json(\"vocab.trg.json\")\n",
    "\n",
    "source_rev = reverse_vocab(source)\n",
    "target_rev = reverse_vocab(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [\"this is so cool\",\n",
    "            \"i am having dinner .\",\n",
    "            \"i am sitting in an aeroplane .\",\n",
    "            \"come let us go for a long drive .\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the string to integers, followed by protobuf encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to integers using source vocab mapping. Out-of-vocabulary strings are mapped to 1 - the mapping for <unk>\n",
    "sentences = [[source.get(token, 1) for token in sentence.split()] for sentence in sentences]\n",
    "f = io.BytesIO()\n",
    "for sentence in sentences:\n",
    "    record = list_to_record_bytes(sentence, [])\n",
    "    write_recordio(f, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/x-recordio-protobuf', \n",
    "                                   Body=f.getvalue())\n",
    "\n",
    "response = response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, parse the protobuf response and convert list of integers back to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_proto_response(received_bytes):\n",
    "    output_file = tempfile.NamedTemporaryFile()\n",
    "    output_file.write(received_bytes)\n",
    "    output_file.flush()\n",
    "    target_sentences = []\n",
    "    with open(output_file.name, 'rb') as datum:\n",
    "        next_record = True\n",
    "        while next_record:\n",
    "            next_record = read_next(datum)\n",
    "            if next_record:\n",
    "                rec = Record()\n",
    "                rec.ParseFromString(next_record)\n",
    "                target = list(rec.features[\"target\"].int32_tensor.values)\n",
    "                target_sentences.append(target)\n",
    "            else:\n",
    "                break\n",
    "    return target_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = _parse_proto_response(response)\n",
    "resp = [\" \".join([target_rev.get(token, \"<unk>\") for token in sentence]) for\n",
    "                               sentence in targets]\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop / Close the Endpoint (Optional)\n",
    "\n",
    "Finally, we should delete the endpoint before we close the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sage.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}