{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation on Amazon SageMaker with Factorization Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference:\n",
    "https://aws.amazon.com/blogs/machine-learning/build-a-movie-recommender-with-factorization-machines-on-amazon-sagemaker/\n",
    "\n",
    "### Download ml-100k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--2020-05-29 13:15:05--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\nResolving files.grouplens.org (files.grouplens.org)...128.101.65.152\nConnecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80...connected.\nHTTP request sent, awaiting response...200 OK\nLength: 4924029 (4.7M) [application/zip]\nSaving to: ‘ml-100k.zip’\n\nml-100k.zip         100%[===================>]   4.70M  2.42MB/s    in 1.9s    \n\n2020-05-29 13:15:07 (2.42 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n\nArchive:  ml-100k.zip\n   creating: ml-100k/\n  inflating: ml-100k/allbut.pl       \n  inflating: ml-100k/mku.sh          \n  inflating: ml-100k/README          \n  inflating: ml-100k/u.data\n  inflating: ml-100k/u.genre         \n  inflating: ml-100k/u.info          \n  inflating: ml-100k/u.item          \n  inflating: ml-100k/u.occupation    \n  inflating: ml-100k/u.user          \n  inflating: ml-100k/u1.base\n  inflating: ml-100k/u1.test         \n  inflating: ml-100k/u2.base         \n  inflating: ml-100k/u2.test\n  inflating: ml-100k/u3.base         \n  inflating: ml-100k/u3.test\n  inflating: ml-100k/u4.base         \n  inflating: ml-100k/u4.test\n  inflating: ml-100k/u5.base\n  inflating: ml-100k/u5.test         \n  inflating: ml-100k/ua.base\n  inflating: ml-100k/ua.test         \n  inflating: ml-100k/ub.base\n  inflating: ml-100k/ub.test         \n"
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/ec2-user/SageMaker/AWS-ML-Certification/__my_study/sagemaker/factorization-movielens/ml-100k\n551\t183\t4\t892776824\n435\t546\t4\t884132942\n514\t169\t5\t875308734\n313\t154\t2\t891014753\n385\t290\t3\t879440674\n94\t369\t1\t891723459\n38\t140\t5\t892430309\n542\t249\t4\t886532432\n686\t299\t5\t879543557\n455\t125\t3\t879109133\n"
    }
   ],
   "source": [
    "%cd ml-100k\n",
    "!shuf ua.base -o ua.base.shuffled\n",
    "!head -10 ua.base.shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\t20\t4\t887431883\n1\t33\t4\t878542699\n1\t61\t4\t878542420\n1\t117\t3\t874965739\n1\t155\t2\t878542201\n1\t160\t4\t875072547\n1\t171\t5\t889751711\n1\t189\t3\t888732928\n1\t202\t5\t875072442\n1\t265\t4\t878542441\n"
    }
   ],
   "source": [
    "!head -10 ua.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "import boto3, csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbUsers=943\n",
    "nbMovies=1682\n",
    "nbFeatures=nbUsers+nbMovies\n",
    "\n",
    "nbRatingsTrain=90570\n",
    "nbRatingsTest=9430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each user, build a list of rated movies.\n",
    "# We'd need this to add random negative samples.\n",
    "moviesByUser = {}\n",
    "for userId in range(nbUsers):\n",
    "    moviesByUser[str(userId)]=[]\n",
    " \n",
    "with open('ua.base.shuffled','r') as f:\n",
    "    samples=csv.reader(f,delimiter='\\t')\n",
    "    for userId,movieId,rating,timestamp in samples:\n",
    "        moviesByUser[str(int(userId)-1)].append(int(movieId)-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataset(filename, lines, columns):\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((lines, columns)).astype('float32')\n",
    "    # Labels are stored in a vector\n",
    "    Y = []\n",
    "    line=0\n",
    "    with open(filename,'r') as f:\n",
    "        samples=csv.reader(f,delimiter='\\t')\n",
    "        for userId,movieId,rating,timestamp in samples:\n",
    "            X[line,int(userId)-1] = 1\n",
    "            X[line,int(nbUsers)+int(movieId)-1] = 1\n",
    "            if int(rating) >= 4:\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "            line=line+1\n",
    "            \n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = loadDataset('ua.base.shuffled', nbRatingsTrain, nbFeatures)\n",
    "X_test, Y_test = loadDataset('ua.test',nbRatingsTest,nbFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(90570, 2625)\n(90570,)\nTraining labels: 49906 zeros, 40664 ones\n(9430, 2625)\n(9430,)\nTest labels: 5469 zeros, 3961 ones\n"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "assert X_train.shape == (nbRatingsTrain, nbFeatures)\n",
    "assert Y_train.shape == (nbRatingsTrain, )\n",
    "zero_labels = np.count_nonzero(Y_train)\n",
    "print(\"Training labels: %d zeros, %d ones\" % (zero_labels, nbRatingsTrain-zero_labels))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "assert X_test.shape  == (nbRatingsTest, nbFeatures)\n",
    "assert Y_test.shape  == (nbRatingsTest, )\n",
    "zero_labels = np.count_nonzero(Y_test)\n",
    "print(\"Test labels: %d zeros, %d ones\" % (zero_labels, nbRatingsTest-zero_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to protobuf and save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket = 'md-labs-bucket'\n",
    "prefix = 'sagemaker/fm-movielens'\n",
    "\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train3')\n",
    "\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test3')\n",
    "\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s3://md-labs-bucket/sagemaker/fm-movielens/train3/train.protobuf\ns3://md-labs-bucket/sagemaker/fm-movielens/test3/test.protobuf\nOutput: s3://md-labs-bucket/sagemaker/fm-movielens/output\n"
    }
   ],
   "source": [
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "test_data  = writeDatasetToProtobuf(X_test, Y_test, bucket, test_prefix, test_key)    \n",
    "  \n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/factorization-machines:latest',\n",
    "              'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest',\n",
    "              'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/factorization-machines:latest',\n",
    "              'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/factorization-machines:latest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ric: host=algo-1, epoch=93, train binary_classification_accuracy <score>=0.748098901099\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=93, train binary_classification_cross_entropy <loss>=0.516370443826\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=93, train binary_f_1.000 <score>=0.77810796945\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.742992401123, \"sum\": 591.742992401123, \"min\": 591.742992401123}}, \"EndTime\": 1590758496.214886, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758495.622356}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8555, \"sum\": 8555.0, \"min\": 8555}, \"Total Records Seen\": {\"count\": 1, \"max\": 8514580, \"sum\": 8514580.0, \"min\": 8514580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 95, \"sum\": 95.0, \"min\": 95}}, \"EndTime\": 1590758496.215105, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 93}, \"StartTime\": 1590758495.62311}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=152964.790011 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=94, batch=0 train binary_classification_accuracy <score>=0.738\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=94, batch=0 train binary_classification_cross_entropy <loss>=0.534860473633\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=94, batch=0 train binary_f_1.000 <score>=0.774526678141\u001b[0m\n\u001b[34m[2020-05-29 13:21:36.791] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 190, \"duration\": 573, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=94, train binary_classification_accuracy <score>=0.748164835165\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=94, train binary_classification_cross_entropy <loss>=0.516036640545\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=94, train binary_f_1.000 <score>=0.778170343339\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.969934463501, \"sum\": 575.969934463501, \"min\": 575.969934463501}}, \"EndTime\": 1590758496.791653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758496.21496}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8646, \"sum\": 8646.0, \"min\": 8646}, \"Total Records Seen\": {\"count\": 1, \"max\": 8605150, \"sum\": 8605150.0, \"min\": 8605150}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 96, \"sum\": 96.0, \"min\": 96}}, \"EndTime\": 1590758496.791914, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 94}, \"StartTime\": 1590758496.215652}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=157132.663463 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=95, batch=0 train binary_classification_accuracy <score>=0.738\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=95, batch=0 train binary_classification_cross_entropy <loss>=0.534521850586\u001b[0m\n\u001b[34m[05/29/2020 13:21:36 INFO 140203272378176] #quality_metric: host=algo-1, epoch=95, batch=0 train binary_f_1.000 <score>=0.774526678141\u001b[0m\n\u001b[34m[2020-05-29 13:21:37.361] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 192, \"duration\": 568, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=95, train binary_classification_accuracy <score>=0.74832967033\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=95, train binary_classification_cross_entropy <loss>=0.515705724695\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=95, train binary_f_1.000 <score>=0.778300516931\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.9441432952881, \"sum\": 569.9441432952881, \"min\": 569.9441432952881}}, \"EndTime\": 1590758497.362467, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758496.791735}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8737, \"sum\": 8737.0, \"min\": 8737}, \"Total Records Seen\": {\"count\": 1, \"max\": 8695720, \"sum\": 8695720.0, \"min\": 8695720}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 97, \"sum\": 97.0, \"min\": 97}}, \"EndTime\": 1590758497.362684, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 95}, \"StartTime\": 1590758496.792497}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=158811.986661 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=96, batch=0 train binary_classification_accuracy <score>=0.737\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=96, batch=0 train binary_classification_cross_entropy <loss>=0.534185668945\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=96, batch=0 train binary_f_1.000 <score>=0.773860705073\u001b[0m\n\u001b[34m[2020-05-29 13:21:37.931] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 194, \"duration\": 567, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=96, train binary_classification_accuracy <score>=0.748428571429\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=96, train binary_classification_cross_entropy <loss>=0.515377546373\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=96, train binary_f_1.000 <score>=0.778411235759\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.0581798553467, \"sum\": 569.0581798553467, \"min\": 569.0581798553467}}, \"EndTime\": 1590758497.932344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758497.36255}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8828, \"sum\": 8828.0, \"min\": 8828}, \"Total Records Seen\": {\"count\": 1, \"max\": 8786290, \"sum\": 8786290.0, \"min\": 8786290}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 98, \"sum\": 98.0, \"min\": 98}}, \"EndTime\": 1590758497.932592, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 96}, \"StartTime\": 1590758497.363256}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=159048.49826 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=97, batch=0 train binary_classification_accuracy <score>=0.737\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=97, batch=0 train binary_classification_cross_entropy <loss>=0.533851806641\u001b[0m\n\u001b[34m[05/29/2020 13:21:37 INFO 140203272378176] #quality_metric: host=algo-1, epoch=97, batch=0 train binary_f_1.000 <score>=0.773860705073\u001b[0m\n\u001b[34m[2020-05-29 13:21:38.539] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 196, \"duration\": 604, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #quality_metric: host=algo-1, epoch=97, train binary_classification_accuracy <score>=0.748538461538\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #quality_metric: host=algo-1, epoch=97, train binary_classification_cross_entropy <loss>=0.51505192851\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #quality_metric: host=algo-1, epoch=97, train binary_f_1.000 <score>=0.778508028999\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 606.8820953369141, \"sum\": 606.8820953369141, \"min\": 606.8820953369141}}, \"EndTime\": 1590758498.5401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758497.93241}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8919, \"sum\": 8919.0, \"min\": 8919}, \"Total Records Seen\": {\"count\": 1, \"max\": 8876860, \"sum\": 8876860.0, \"min\": 8876860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 99, \"sum\": 99.0, \"min\": 99}}, \"EndTime\": 1590758498.540346, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 97}, \"StartTime\": 1590758497.933188}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=149143.411784 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #quality_metric: host=algo-1, epoch=98, batch=0 train binary_classification_accuracy <score>=0.737\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #quality_metric: host=algo-1, epoch=98, batch=0 train binary_classification_cross_entropy <loss>=0.533520080566\u001b[0m\n\u001b[34m[05/29/2020 13:21:38 INFO 140203272378176] #quality_metric: host=algo-1, epoch=98, batch=0 train binary_f_1.000 <score>=0.773860705073\u001b[0m\n\u001b[34m[2020-05-29 13:21:39.136] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 198, \"duration\": 594, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=98, train binary_classification_accuracy <score>=0.748571428571\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=98, train binary_classification_cross_entropy <loss>=0.514728737967\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=98, train binary_f_1.000 <score>=0.778534923339\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 596.5480804443359, \"sum\": 596.5480804443359, \"min\": 596.5480804443359}}, \"EndTime\": 1590758499.137468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758498.540171}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9010, \"sum\": 9010.0, \"min\": 9010}, \"Total Records Seen\": {\"count\": 1, \"max\": 8967430, \"sum\": 8967430.0, \"min\": 8967430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}}, \"EndTime\": 1590758499.137741, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 98}, \"StartTime\": 1590758498.540888}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=151714.873539 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=99, batch=0 train binary_classification_accuracy <score>=0.737\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=99, batch=0 train binary_classification_cross_entropy <loss>=0.533190429687\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=99, batch=0 train binary_f_1.000 <score>=0.773860705073\u001b[0m\n\u001b[34m[2020-05-29 13:21:39.712] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 200, \"duration\": 572, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=99, train binary_classification_accuracy <score>=0.748648351648\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=99, train binary_classification_cross_entropy <loss>=0.514407815787\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, epoch=99, train binary_f_1.000 <score>=0.778596250085\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.748648351648\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, train binary_classification_cross_entropy <loss>=0.514407815787\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.778596250085\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.5458602905273, \"sum\": 574.5458602905273, \"min\": 574.5458602905273}}, \"EndTime\": 1590758499.712879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758499.137562}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9101, \"sum\": 9101.0, \"min\": 9101}, \"Total Records Seen\": {\"count\": 1, \"max\": 9058000, \"sum\": 9058000.0, \"min\": 9058000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 101, \"sum\": 101.0, \"min\": 101}}, \"EndTime\": 1590758499.713067, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 99}, \"StartTime\": 1590758499.138308}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #throughput_metric: host=algo-1, train throughput=157551.638889 records/second\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 WARNING 140203272378176] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] Pulling entire model from kvstore to finalize\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2.128124237060547, \"sum\": 2.128124237060547, \"min\": 2.128124237060547}}, \"EndTime\": 1590758499.715448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758499.712945}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] Saved checkpoint to \"/tmp/tmpfIMVTZ/state-0001.params\"\u001b[0m\n\u001b[34m[2020-05-29 13:21:39.722] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 60096, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n\u001b[34m[2020-05-29 13:21:39.759] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 37, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Total Records Seen\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1590758499.760098, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758499.722615}\n\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #test_score (algo-1) : ('binary_classification_accuracy', 0.6972428419936373)\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #test_score (algo-1) : ('binary_classification_cross_entropy', 0.5771159976057132)\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #test_score (algo-1) : ('binary_f_1.000', 0.7440609592111161)\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, test binary_classification_accuracy <score>=0.697242841994\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, test binary_classification_cross_entropy <loss>=0.577115997606\u001b[0m\n\u001b[34m[05/29/2020 13:21:39 INFO 140203272378176] #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.744060959211\u001b[0m\n\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 60198.023080825806, \"sum\": 60198.023080825806, \"min\": 60198.023080825806}, \"setuptime\": {\"count\": 1, \"max\": 51.10311508178711, \"sum\": 51.10311508178711, \"min\": 51.10311508178711}}, \"EndTime\": 1590758499.760893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1590758499.715503}\n\u001b[0m\n\n2020-05-29 13:21:50 Uploading - Uploading generated training model\n2020-05-29 13:21:50 Completed - Training job completed\nTraining seconds: 109\nBillable seconds: 109\n"
    }
   ],
   "source": [
    "role = 'arn:aws:iam::868024899531:role/service-role/AmazonSageMaker-ExecutionRole-20200523T071121'\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                #    get_execution_role(), \n",
    "                    role,\n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_prefix,\n",
    "                    sagemaker_session=sagemaker.Session())\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=nbFeatures,\n",
    "                      predictor_type='binary_classifier',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=100)\n",
    "\n",
    "fm.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Estimator is not associated with a training job",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9dcfa92983bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfm_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.c4.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/python2/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0mendpoint\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobtain\u001b[0m \u001b[0minferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_latest_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0mendpoint_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/python2/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36m_ensure_latest_training_job\u001b[0;34m(self, error_message)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Estimator is not associated with a training job"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'fm_predictor' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b9441ceeb521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfm_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfm_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm_serializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfm_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_deserializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fm_predictor' is not defined"
     ]
    }
   ],
   "source": [
    "def fm_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        js['instances'].append({'features': row.tolist()})\n",
    "    #print js\n",
    "    return json.dumps(js)\n",
    "\n",
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer\n",
    "fm_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fm_predictor.predict(X_test[1000:1010].toarray())\n",
    "print(result)\n",
    "print (Y_test[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}